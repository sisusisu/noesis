<?xml version="1.0"  encoding="ISO-8859-1" ?> 
<!DOCTYPE sys-ents [ <!ENTITY bibliography SYSTEM "bibliography.xml"> ]> 
<?xml-stylesheet type="text/xsl" href="../book.xsl"?>


<document>
&bibliography;
<title>Network Metrics</title>

<quote author="Charles Goodhart" source="Monetary Relationships: A View from Threadneedle Street (1975)">
Goodhart's Law: Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes.
</quote>

<text>
In other words: "Once a social or economic indicator or other surrogate measure is made a target for the purpose of conducting social or economic policy, then it will lose the information content that would qualify it to play that role" @ Wikipedia.
</text>

<text>
Many of the key structural measures have grown out of insights of researchers trying to describe empirical phenomena and are motivated by central concepts in social theory <cite>Wasserman and Faust 1994</cite>. Many of the formal concepts in network analysis were introduced in the 1950's and 1960's to describe properties of social structures.
</text>

<text>
Local metrics quantify the properties of the local neighborhoods of individual nodes, while global metrics can capture network communication properties.
</text>

<document>
<tag>centrality</tag>
<title>Centrality measures</title>

<text>
Local centrality measures let us infer the potential influence of individual nodes or links within a network and quantify their centrality with respect to the network structure (and information flow therein). In other words, centrality measures try to highlight the most influential nodes within a network, either because their loss might prove to be disruptive for the rest of the network or just because they play key roles within the communication patterns that take place on the network.
</text>

<text>
L: Power. The power of a node is proportional to its degree (number of links connecting
it to the network) influence (link values); and betweenness or closeness;
the power of a network is proportional to the number and strength of
its nodes and links. For example, Metcalf's law states that the power of a
network is proportional to the square of the number of nodes it contains
[e.g., the maximum number of links that a network with n nodes can contain
is n(n2-1)/2, which is approximately n2]. The influence a person exerts on a
group is proportional to the position, number, and power of colleagues the
person has within the group, such as the person’s connectivity. The power of
a corporation, within an industry or market, is proportional to the number
of customers (links) that it has, or its intermediary position within the
industry. Power is a subtle but important organizing principle in most networks,
but it is often called something else, such as influence, signal strength,
or infection rate.
</text>

<text>
The use of a particular metric to characterize the centrality of a node within a given network makes assumptions on the nature of the information flow or the dynamic processes on the network <cite>Borgatti 2005</cite>.
</text>


<document>
<tag>centrality-degree</tag>
<title>Node degree</title>

<text>
Node degree is the simplest indicator of the node importance within the network. As a matter of fact, node degree, or strength in weighted networks, is a simple measure of direct interaction. The balance of in-degree and out-degree might also indicate the role of the node within the network (e.g. whether it primarity sends or receives information).
</text>

<text>
Node degree is highly informative in networks where a small fraction of nodes collect the vast majority of links (a.k.a. scale-free networks). In such networks, high-degree nodes (often called hubs) are essential for maintaining the network connectivity and targeted attacks might be fatal for the network to continue its operation. Just think of major airports and the disruptions they cause on the air traffic when they have to be closed.
</text>

<text>
Degree centrality for undirected graphs:
</text>

<equation>
C_{degree}(i) = \frac{degree(i)}{n-1}
</equation>

<text>
Degree centrality for undirected graphs:
</text>

<equation>
C'_{degree}(i) = \frac{degree_{out}(i)}{n-1}
</equation>

<text>
Value within <eqn>[0,1]</eqn>.
</text>


</document>


<document>
<tag>centrality-closeness</tag>
<title>Closeness</title>

<text>
Many centrality metrics are based on shortest paths. The idea behind them is that a node is central to the network if it has some control over the most efficient routes in the flow of information within the network. This potential control, obviously, comes from the node participation in many of the network shortest paths <cite>Freeman 1978</cite>.
</text>

<text>
The closeness centrality of a given node is the inverse of the average path length between that node and the other nodes in the network.
</text>

<equation>
C_{closeness}(i) = \frac{ n-1 }{ \sum_{j=1}^{n} distance(i,j)}
</equation>

<text>
Value within <eqn>[0,1]</eqn>.
</text>

<text>
A node with a high closeness centrality lies close to the rest of the nodes in the network and, since it can reach them through short paths, it can exert a stronger influence on them than other nodes with a lower closeness centrality.
</text>

<text>
L: Closeness—as defined here—is not a perfect measure of an intermediary’s power
over others. Consider the case of a symmetric graph. It
is highly likely that several shortest paths exist between two arbitrarily chosen source
and destination nodes.
</text>

</document>


<document>
<tag>centrality-betweenness</tag>
<title>Betweenness</title>

<text>
As it happened with closeness, betweenness is also based on the network shortest paths.
</text>

<text>
IDEA: If non-adjacent nodes j and k want to interact and node i is on the path between them, then i may have some control over their interactions.
</text>

<text>
The betweenness centrality of a given node is degined as the fraction of all the shortest paths within the network that go through the node.
</text>

<text>
Let <eqn>p_{jk}</eqn> be the number of shortest paths between nodes <eqn>j</eqn> and <eqn>k</eqn> and <eqn>p_{jk}(i)</eqn> the number of shortest paths between nodes <eqn>j</eqn> and <eqn>k</eqn> that pass through <eqn>i</eqn>.
</text>

<text>
Betweenness centrality for undirected graphs:
</text>

<equation>
betweenness(i) = \sum_{j&lt;k} \frac{ p_{jk}(i) }{ p_{jk} }
</equation>


<text>
<eqn>betweenness(i)</eqn> is between <eqn>0</eqn>, when <eqn>i</eqn> appears in no shortest path between any pair <eqn>(j,k)</eqn>, and <eqn>(n-1)(n-2)/2</eqn>, which is the number of pairs not including <eqn>i</eqn>.
</text>

<text>
If we want betweenness to be between 0 and 1, we normalize:
</text>

<equation>
C_{betweenness}(i) = \frac { 2 \sum_{j&lt;k} \frac{ p_{jk}(i) }{ p_{jk} } } { (n-1)(n-2) }
</equation>


<text>
Betweenness centrality for directed graphs:
</text>

<equation>
C'_{betweenness}(i) = \frac { \sum_{j \neq k} \frac{ p_{jk}(i) }{ p_{jk} } } { (n-1)(n-2) }
</equation>

<text>
Since now there are <eqn>(n-1)(n-2)</eqn> pairs if we consider that a path from <eqn>j</eqn> and <eqn>k</eqn> is different than a path from <eqn>k</eqn> to <eqn>j</eqn>.
</text>

<text>
A node with a high betweenness centrality can control information because it lies at the intersection of many short paths (e.g. key midfield player in soccer).
</text>

<text>
++ <cite>Barthelemy 2004</cite>
</text>

<text>
Unlike the closeness measure, betweenness can also be computed for non-connected graphs.
</text>

<text>
It should be noted that both closeness and betweenness only consider what happens on the shortest paths between nodes, ignoring the network traffic that might occur on longer paths that also contribute to global network communication patterns. Moreover, betweenness assumes that flow along the shortest path is unaffected by bifurcations and confluences along the path. Matrix-based centrality metric take them into account.
</text>

</document>


<document>
<tag>centrality-participation</tag>
<title>Participation</title>

<text>
When communities are identified within a network, within-module and between-modules connectivity can also provide information about the specific contributions of individual nodes. Participation coefficients measure the diversity of between-modules connections <cite>Guimera and Amaral 2005</cite> <cite>Guimera et al. 2007</cite>.
</text>

<text>
Connector hubs are high-degree nodes that maintain a diverse set of between-modules connections and have a high participation coefficient. Provincial hubs, however, are also high-degree nodes but mostly participate in connections within their community, hence they have a low participation coefficient. Although provincial hubs are unlikely to play a key role in the global network communication patterns, they still play a key role in the maintenance of their communities' cohesion.
</text>

</document>




<document>
<tag>centrality-prestige</tag>
<title>Prestige</title>

<text>
Look at in-links rather than out-links (only for directed graphs)...
</text>

<text>
<b>Degree prestige</b>: A node is prestigious if it receives many in-links (vs. degree centrality).
</text>

<equation>
P'_{degree}(i) = \frac{degree_{in}(i)}{n-1}
</equation>

<text>
<b>Proximity prestige</b>: Generalizes degree prestige by considering non-adjacent nodes (vs. closeness).
</text>

<text>
First, we compute the average distance to <eqn>i</eqn>:
</text>

<equation>
\frac{ \sum_{j \in I_i} distance(j,i) }{ |I_i| }
</equation>

<text>
where <eqn>I_i</eqn> is the influence domain of <eqn>i</eqn>, i.e. the set of nodes that can reach node <eqn>i</eqn>.
</text>

<text>
Then, we normalize by considering the ratio of nodes that can reach <eqn>i</eqn> with respect to their average distance:
</text>

<equation>
P'_{proximity}(i) = \frac { \frac{ |I_i| }{ n-1 } }{ \frac{ \sum_{j \in I_i} distance(j,i) }{ |I_i| } }
</equation>

<text>
<b>Rank prestige</b>, when we consider the prominence of nodes that link to the node whose prestige we are trying to evaluate...
</text>

<equation>
P'_{rank}(i) = A_{1i} P'_{rank}(1) + A_{2i} P'_{rank}(2) + ... + A_{ni} P'_{rank}(n)
</equation>

<text>
where <eqn>A</eqn> is the adjacency matrix (i.e. <eqn>A_{ji}</eqn> is 1 if there is an arc between <eqn>j</eqn> and <eqn>i</eqn>, 0 otherwise).
</text>

<text>
The expression above leads to the following equation in matrix form:
</text>

<equation>
P'_{rank} = A^T P'_{rank}
</equation>

<text>
where <eqn>P'_{rank}</eqn> is a column vector containing all the rank prestige values: <eqn>P_{rank} = ( P_{rank}(1) P_{rank}(2) ... P_{rank}(n) )^T</eqn>.
</text>

<text>
The above matrix equation is the one employed for finding the eigensystem of <eqn>A^T</eqn> and <eqn>P'_{rank}</eqn> is an eigenvector of <eqn>A^T</eqn>. This equation is also at the heart of all the matrix-based centrality measures we will study in the next two sections.
</text>

</document>

<document>
<tag>centrality-matrix</tag>
<title>Matrix-based centrality measures</title>

<text>
++ <cite>Page et al. 1998</cite>
</text>

<text>
IDEA: Since a page can link to many pages, its score should be split among all the pages it points to (different than the rank prestige definition above).
</text>

<equation>
PageRank(i) = \sum_{(j,i) \in E} \frac { PageRank(j) } { degree_{out}(j) }
</equation>

<text>
The above expression leads to a system of n linear equations with n unknowns, which can be stated in matrix form as the characteristic equation of an eigensystem and solved using an iterative algorithm. The solution is an eigenvector with an eigenvalue of 1. When some conditions hold, 1 corresponds to the largest eigenvalue and the PageRank vector is the principal eigenvector, which can be found using power iteration, a well-known technique. In order to meet such conditions, a Markov chain model of the graph is built whose unique stationary probability distribution corresponds to the principal eigenvector with eigenvalue of 1.
</text>

<text>
For the Markov model to have an unique stationary distribution, its stochastic transition matrix must be irreducible and aperiodic. Let us see how it can be derived from the graph adjacency matrix. 
</text>

<text>
1. The entries in each row of a stochastic transition matrix for a finite Markov chain must be non-negative and sum up to 1, which requires all nodes to have, at least, one out-link. Since some nodes might not have out-links, we could remove those pages when performing the initial PageRank computation or add a complete set of outgoings links from each node without out-links to all the nodes in the network (i.e. 1/n transition probability). 
</text>

<text>
2. For the matrix to be irreducible, the graph it represents must be strongly connected.
</text>


<text>
3. A Markov chain is periodic when there exists a directed cycle the chain must traverse.
</text>

<text>
Problems 2 and 3 can be dealt with using a single strategy. Namely, adding a link from each page to every page and giving each link a small transition propability. This augmented transition matrix becomes irreducible (it is strongly connected) and also aperiodic. In the PageRank stochastic model, an out-link is randomly chosen with probability d and we jump to a random page without a link with probability 1-d, which leads to the following equation:
</text>

<equation>
P = \left ( (1-d) \frac{E}{n} + dA^T \right ) P
</equation>

<text>
where <eqn>E=ee^T</eqn> and <eqn>e</eqn> is a column vector of 1's, hence <eqn>E</eqn> is an <eqn>n \times n</eqn> square matrix of ones, and <eqn>A</eqn> is an stochastic matrix derived from the graph adjacency matrix as described in the above discussion.
</text>

<text>
By multiplying by n on both sides, we obtain the PageRank formula
</text>

<equation>
P = (1-d) e + d A^T P
</equation>

<text>
which is equivalent to
</text>

<equation>
P(i) = (1-d)  + d \sum_{(j,i) \in E} \frac { P(j) } { degree_{out}(j) }
</equation>

<text>
where <eqn>d</eqn> is known as the damping factor, a value between 0 and 1, set at 0.85 in <cite>Page et al. 1998</cite>.
</text>

<text>
PageRank values can then be computed using the power iteration method:
</text>

<code>
PageRank = e/n

repeat
  prev = P
  PageRank = (1-d)*e + d*A'*P
until ||PageRank-prev|| &lt; epsilon
</code>

<text>
NOTE: As in the standard Matlab notation, A' indicates the transpose of A.
</text>

<text>
<cite>Brin and Page 1998</cite> reports that the algorithm converges to an acceptable tolerance after just 52 iterations using a 322 million link network. Other advantages include its robustness against fake links, which will come from non-important nodes, and its query independence (it can be precomputed and used in combination with other factors in search engines such as Google).
</text>


<text>
++ <cite>Katz 1953</cite>
</text>

<text>
++ <cite>Bonacich 1972</cite> <cite>Bonacich 2007</cite>: Eigenvector centrality (takes into account interactions of different path lengths and their dispersion, relying on walks rather than shortest paths).
</text>



</document>


<document>
<tag>centrality-hubs</tag>
<title>Hubs and authorities</title>

<text>
Citation analysis: co-citation and bibliographic coupling
</text>

<text>
N: It is sometimes convenient to turn a directed network into an undirected one for the purposes of analysis. Two measures of vertex similarity...

- The cocitation of two vertices i and j in a directed network is the number of vertices that have outgoing edges pointing to both i and j. In the language of citation networks, for instance, the cocitation of two papers is the number of other papers that cite both.

- Bibliographic coupling is similar to cocitation. The bibliographic coupling of two vertices in a directed network is the number of other vertices to which both point. In a citation network, for instance, the bibliographic coupling of two papers i and j is the number of other papers that are cited by both i and j. 
</text>

<text>
<b>Co-citation</b>: When two papers are cited by a third one, they are somehow related even though they do not cite each other. Co-citation is a similarity measure defined as the number of papers that co-cite a given pair of papers:
</text>

<equation>
CC_{ij} = \sum_{k=1}^{n} A_{ki} A_{kj}
</equation>

<text>
<eqn>CC_{ij}</eqn> is the co-citation matrix, which is symmetric.
</text>

<text>
Co-citation network:
N: ... we can define a cocitation network in which there is an edge between i and j if Cij &gt; 0, for i \neq j, i.e., an edge between any two vertices that are cocited in the original directed network. (We enforce the constraint that i \neq j because the cocitation network is conventionally defined to have no self-edges, even though the diagonal elements of the cocitation matrix are in general nonzero—see below.) ... we can also make the cocitation network a weighted network with positive integer weights on the edges equal to the corresponding elements Cij. T... In citation networks of academic papers, for instance, strong cocitation between papers is often a good indicator of papers that deal with related topics—if two papers are often cited together in the same bibliography they probably have something in common. And the more often they are cited together, the more likely it is that they are related.

... The cocitation matrix thus plays a role similar to an adjacency matrix for the cocitation network. There is however one aspect in which the cocitation matrix differs from an adjacency matrix: its diagonal elements. The diagonal elements of the cocitation matrix are equal to  the total number of edges pointing to i—the total number of papers citing i.
</text>

<text>
<b>Bibliographic coupling</b> mirrors co-citation by linking papers that cite the same articles (i.e. when two papers cite a third one, they are also related even though they do not cite each other). Let as define <eqn>BC_{ij}</eqn> as the number of papers that are cited by both <eqn>i</eqn> and <eqn>j</eqn>:
</text>

<equation>
BC_{ij} = \sum_{k=1}^{n} A_{ik} A_{jk}
</equation>

<text>
<eqn>BC_{ij}</eqn> defines the bibliographic coupling matrix, which is also symmetric.
</text>


<text>
N: Bibliographic coupling, like cocitation, can be a useful measure of connection between vertices. In a citation network, for example, if two papers cite many of the same other papers it is often a good indication that they deal with similar subject matter, and the number of common papers cited can be an indicator of how strongly they overlap
</text>

<text>
N: n a citation network, for instance, two papers can only have strong cocitation if they are both well cited and hence strong cocitation is limited to influential papers, review articles, books, and similar highly cited items. Conversely, two papers can only have strong bibliographic coupling if they both cite many others, i.e., if they have large bibliographies. In practice, the sizes of bibliographies vary less than the number of citations papers receive, and hence bibliographic coupling is a more uniform indicator of similarity between papers than cocitation... the cocitation of two papers can change over time as the papers receive new citations, whereas bibliographic coupling is fixed from the moment the papers are published.
</text>

<text>
The HITS algorithm is related to these two citation analysis metrics. HITS stands for Hypertext Induced Topic Search. Unlike PageRank, HITS is query dependent. For each query, HITS expands the list of relevant pages returned by a search engine and ranks those pages according to two criteria: authority ranking and hub ranking.
</text>

<text>
Authorities receive many in-links, whereas hubs contain many out-links. The hubs and authorities found by the HITS algorithm are related to co-citation and bibliographic coupling matrices.
</text>


<text>
++ <cite>Kleinberg 1998</cite> <cite>Kleinberg 1999a</cite> <cite>Kleinberg 1999b</cite>
</text>

<text>
IDEA: A good hub links to many good authorities. Likewise, a good authority is pointed to by many good hubs. This mutual reinforcement is exploited by the HITS algorithm.
</text>

<text>
After expanding the set of pages with those pointed by or pointing to pages in the search engine result set, HITS assigns every page an authority score and a hub score...
</text>


<equation>
authority(i) = \sum_{(j,i) \in E} hub(j)
</equation>

<equation>
hub(i) = \sum_{(i,j) \in E} authority(j)
</equation>

<text>
In matrix form:
</text>

<equation>
a = A^T h
</equation>

<equation>
h = A a
</equation>

<text>
The computation of authority and hub scores is performed using the power iteration method, as happened with PageRank:
</text>

<equation>
a = A^T A a = CC a
</equation>

<equation>
h = A A^T h = BC a
</equation>


<text>
Co-citation, CC, and bibliographic coupling, BC, matrices can be computed beforehand, since they are involved in the iterative computation of hub and authority scores...
</text>

<text>
In pseudocode:
</text>

<code>
authority = e
hub = e

CC = A' * A
BC = A * A'

repeat
  // Previous values
  prevA = authority
  prevH = hub
  // Iteration
  authority = CC * authority
  hub = BC * hub
  // Normalization
  authority = authority / ||authority||
  hub = hub / ||hub||
until (||authority-prevA|| &lt; epsilonA) and (||hub-prevH|| &lt; epsilonH)
</code>



<text>
PROBLEM: For certain graphs, different initializations result in different authority and hub vectors (ref. Farahat et al.: "Authority rankings for HITS, PageRank, and SALSA: Existence, uniqueness, and effect of initialization," SIAM Journal on Scientific Computing 27(4):1181-1201, 2006). This problem is caused by the fact that <eqn>A^T A</eqn> is reducible (ref. Langville et Meyer: "Deeeper inside PageRank", Intenet Mathematics 1(3):335-380, 2004).
</text>

</document>


</document>


<document>
<tag>ranking</tag>
<title>Ranking</title>

<text>
e.g. Web search (10-30 links from millions of web pages containing some given words)
</text>

<document>
<tag>ranking-pagerank</tag>
<title>PageRank</title>

<text>
++ <cite>Page et al. 1998</cite> <cite>Brin and Page 1998</cite>
</text>


<text>
++ Facebook has its own algorithm, EdgeRank, which (in conjunction with September’s addition, GraphRank) determines which items appear at the top of an individual's news feed. EdgeRank is based on many variables, including who Facebook thinks are a user's closest friends and how many people have interacted with a piece of content.

@ FT Tech Hub:
The unexpected impact of Facebook’s <q>seamless sharing</q> on newspaper sites.
November 18, 2011 4:52 pm by Tim Bradshaw.

 <url>http://blogs.ft.com/fttechhub/2011/11/unexpected-impact-facebook-newspaper-sites</url>
 <url>http://econsultancy.com/uk/blog/7885-edgerank-the-most-important-algorithm-you-ve-never-heard-of</url>
</text>

<text>
++ Other ranking method, based on the user search log: BrowseRank (SIGIR'2008)
++ TrustRank (VLDB'2004).
</text>

<text>
++ Considering time (recency search): TS-Rank, time-sensitive ranking (ICDM'2008) and chapter in <cite>Yu et al. 2010</cite> @ p.187-209, also described within a subsection in <cite>Liu 2011</cite> @ p. 286-288.
</text>

</document>

<document>
<tag>ranking-HITS</tag>
<title>HITS</title>

<text>
++ <cite>Kleinberg 1998</cite> <cite>Kleinberg 1999a</cite> <cite>Kleinberg 1999b</cite>
</text>

<text>
CITATION ANALYSIS: Top authorities are like influential research papers cited by many other papers. Top hubs correspond to relevant surveys citing many influential papers. 
</text>


<text>
Sometimes, we might be interested in finding hubs and authorities within densely-linked collections (HITS returns just the major cluster corresponding to top-ranked hubs and authorities). These might correspond to non-principal eigenvectors, which can be computed using other numerical computing algorithms, such as orthogonal iteration or QR iteration. Examples: polysemic words, controversial issues (reflected as polarized groups within a network).
</text>

<text>
NOTE: Minor perturbations on the network can greatly influcence hub and authority scores, whereas they have little effect on PageRank scores 
</text>

<text>
(ref. Ng, Zheng, Jordan: "Stable algorithms for link analysis", SIGIR'2001) introduced the random jump step of PageRank into HITS to improve its stability.
</text>

<text>
(ref. Lempel, Moran: "The stochastic approach for link-structure analysis (SALSA) and the TKC effect." Computer Networks 33(1-6):387-401, 2000 ) proposed SALSA, a stochastic algorithm for link structure analysis that combines PageRank and HITS features to improve authority and hub computation by using two Markov chains: one for hubs and a different one for authorities.
</text>

</document>

<document>
<tag>ranking-blocks</tag>
<title>Block-level link analysis</title>

<text>
Multi-topic pages... (+ the problem of topic drifting, i.e. returning pages that have nothing to do with the topic search just because they are collected due to the presence of out-links that connect to them or even spamming in-links).
</text>

<text>
(ref. Chakrabarti: "Integrating the document object model with hyperlinks for enhanced topic distillation and information extraction" WWW'2001, 221-220) segments the page based on its DOM tree structure to identify the subtrees that are more related to a query topic.
</text>

<text>
(ref. Cai, Yu, Wen, Ma: "Block-based web search", SIGIR'2004) segments each Web page into different blocks, which are given importance value according, for instance, to their location. This importance value is then used to weight the links in the HITS or PageRank computation, thus reducing the impract of unimportant links.
</text>

</document>

</document>



<document>
<tag>similarity</tag>
<title>Similarity</title>


<document>
<tag>similarity-assortativity</tag>
<title>Assortativity</title>

<text>
A measure based on degree <cite>Newman 2002</cite>, defined as the correlation coefficient for the degrees of neighboring nodes, indicates whether edges tend to link nodes of similar degrees (positive assortativity) or high-degree nodes preferentially connect to low-degree nodes (negative assortativity).
</text>

</document>


<document>
<tag>similarity-structural</tag>
<title>Structural equivalence</title>
</document>

<document>
<tag>similarity-regular</tag>
<title>Regular equivalence</title>
</document>

</document>


<document>
<tag>connectivity</tag>
<title>Connectivity</title>

<text>
++ <cite>Barzel and Biham 2009</cite>
</text>

<document>
<tag>connectivity-density</tag>
<title>Density</title>

<text>
L: Density is the ratio of the number of actual links to the maximum number possible.
</text>

<equation>
density(G) = \frac{m}{n(n-1)}
</equation>

</document>

<document>
<tag>connectivity-path-length</tag>
<title>Average path length</title>

<text>
L: Path length is the shortest path between two nodes, and average path length is the average over all shortest paths.
</text>

<text>
The average path length of a network (a.k.a. characteristic path length) is defined as the average path length over all (shortest) direct paths between all pairs of nodes in the network.
</text>

<text>
L: Let <eqn>d_{i,j}</eqn> the length of the direct path between node <eqn>v_i</eqn> and <eqn>v_j</eqn>. Then, the average over all <eqn>d_{i,j}</eqn> is just
</text>

<equation>
avgPathLength(G) = \sum_{i} \sum_{j} \frac{d_{i,j}}{n(n-1)}
</equation>

<text>
Since we have to find all paths between nodes in the network, we could resort to an all-pairs shortest path algorithm. However, if link costs are equal, a simple breadth-first traversal suffices and computes the average path length in quadratic time.
</text>

<text>
L: In terms of the path matrix, row v of the path matrix corresponds to starting node v, and the elements of row v correspond to the other nodes in the network. If a node is not reachable from node v, then the length of the path between them is zero. We construct the path matrix, row-by-row, and then compute the average value of the nonzero elements of the path matrix. Averaging over all paths from all pairs of nodes yields the characteristic or average path length. 
</text>

<text>
i.e. <eqn>O(n^2)</eqn> algorithm
</text>

<note>
<text>
L: While we are computing the network characteristic path legth, we can also compute its diameter and radius as a byproduct of the path length calculation. Diameter is the largest value of k in the network, and a node’s radius is the maximum distance of this node from all others. The node with the smallest radius is the central node—it is as close or closer to all nodes than any other node (i.e. computes a measure of centrality for all nodes, and designates the most central node as the network’s center). We could also calculate closeness as a byproduct of finding all paths through the
network...
</text>
</note>

</document>


<document>
<tag>connectivity-efficiency</tag>
<title>Link efficiency</title>

<text>
L: Link efficiency is used for comparing the efficiency of a network in terms of its average path length and number of links. A link-efficient
network utilizes its links in an efficient manner to reduce average path length. In many applications of network science we want the shortest average path length possible while simultaneously conserving the number of links. 

++ efficient network are sparse and efficiently utilize links to reduce average path length.

We define link efficiency E(G) as follows:
</text>

<equation>
efficiency(G) =  \frac{m - avgPathLength(G)}{m} = 1 - \frac{avgPathLength(G)}{m}
</equation>

<text>
L: this metric ranges from zero, when the
average path length is m, to 100%, when the average path length is zero. In
the extreme case, E = 1.0, every link contributes to link efficiency. When E = 0,
the average path length equals m, which is the worst path length possible. Link
efficiency is a measure of how effective links are at shortening characteristic path
length. Higher values of E correspond to networks that are more efficient.
</text>

<text>
L: In general, we are interested in efficient utilization of links as the size of a network
increases. A network is scalable if link efficiency approaches 100% as network size
n approaches infinity. Otherwise, a network is non-scalable.
</text>

</document>

</document>

<document>
<tag>modularity</tag>
<title>Modularity</title>


<text>
Networks with high levels of clustering are often composed of local communities or modules, which consist of densely connected sets of nodes. A module is separated from other modules in the sense that most links connect nodes within the module and only a few links extend beyond the module boundaries. </text>

<text>
A measure of network modularity characterizes the balance of within-module and between-modules connections.
</text>

<text>
++ <cite>Girvan and Newman 2002</cite> <cite>Newman 2006</cite>
</text>

</document>



<document>
<tag>metrics-notes</tag>
<title>Bibliographic notes</title>

<text>
Despite their overlap and partial redundancy, different metrics provide unique information about individual nodes and their neighborhoods, hence each one is suitable for particular applications...
</text>

<text>
++ Studies <cite>Varlamis et al. 2010</cite> <cite>Maiya and Berger-Wolf 2010b</cite> <cite>Rubinov and Sporns 2010</cite>
</text>

<text>
Both HITS and PageRank were presented in 1998: HITS at the 9th ACM-SIAM Symposium on Discrete Algorithms in January and PageRank at the 7th International World Wide Web Conference in April.
</text>


<text>
Popular Science books
++ "Who's #1? The Science of Rating and Ranking", by Amy N. Langville and Carl D. Meyer, Princeton University Press, 2012. ISBN 0691154228
(ranking methods and evaluation techniques)
++ "Google PageRank and Beyond: The Science of Search Engine Rankings", by Amy N. Langville and Carld D. Meyer, Princeton University Press, 2006. ISBN 0691122024 (2012 paperback edition, ISBN 0691152667)
(PageRank + HITS)
</text>


</document>


</document>

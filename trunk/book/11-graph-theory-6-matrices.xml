<?xml version="1.0"  encoding="ISO-8859-1" ?> 
<?xml-stylesheet type="text/xsl" href="../book.xsl"?>


<!-- Graphs as matrices -->

<document>
<tag>graph-theory-matrix</tag>
<title>Graphs as matrices</title>

<text>
Up to this point, we have described graphs by means of sets of nodes and ordered pairs and we have illustrated them with the help of simple line diagrams. However, a matrix representation of graphs is also possible, as we will see in this section.
</text>

<text>
Whereas set theory might be especially suitable for providinf formal definitions and proving theorems, for data analysis a matrix representation is
more useful.
</text>

<document>
<tag>graph-theory-matrix-adjacency</tag>
<title>The adjacency matrix</title>

<text>
Let G be a graph with n nodes. The adjacency matrix of the graph G is the <eqn>n \times n</eqn> binary matrix <eqn>A(G) = [a_{ij}]</eqn> where
</text>

<equation>
a_{ij} = 
\left \{
\begin{matrix}
 1 &amp; if &amp; v_iv_j \in E(G)\\ 
 0 &amp; if &amp; v_iv_j \notin E(G)
\end{matrix}
\right.
</equation>

<text>
++ the main diagonal (sometimes leading diagonal or major diagonal or primary diagonal or principal diagonal) 
</text>

<text>
For example, the adjacency matrix of the complete graph <eqn>K_5</eqn> is
</text>

<equation>
A(K_5) =
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 
\end{bmatrix}
</equation>

<text>
For complete graphs, every off-diagonal cell in the matrix is 1.
</text>


<text>
Whereas the adjacency matrix of the complete bipartite graph <eqn>K_{3,3}</eqn> is
</text>

<equation>
A(K_{3,3}) =
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}
</equation>

<text>
In linear algebra, a block matrix or partitioned matrix is a matrix broken into sections called blocks. Considering that a block diagonal matrix is a block matrix which is a square matrix, and having main diagonal blocks square matrices, such that the off-diagonal blocks are zero matrices, we could say that, by properly rearranging the rows and columns in the matrix, the adjacency matrix of a s-partite graph is a block antidiagonal matrix, since the diagonal of a square matrix from the top right to the bottom left corner is called antidiagonal, counterdiagonal, secondary diagonal, or minor diagonal. 
</text>

<text>
In fact, bipartite graphs could be represented more succinctly by a smaller matrix, of size <eqn>|V_1| \times |V_2|</eqn>, usually called the <term>biadjacency matrix</term> (or <term>affiliation matrix</term> in social network analysis terms when the bipartite graph represents an affiliation network). The biadjacency matrix <eqn>B</eqn> of a bipartite graph corresponds to the upper right quadrant of the graph adjacency matrix when it is represented as (i.e. all ones for complete bipartite graphs).
</text>

<equation>
A(G) =
\begin{bmatrix}
0   &amp; B \\
B^t &amp; 0  \\
\end{bmatrix}
</equation>

<text>
Biadjacency matrices are specially suitable for weighted graphs, when binary values are replaced by edge weights, since they are suitable for representing matching problems.
</text>


<text>
N: Such weighted or valued networks can be represented by giving the elements of the adjacency matrix values equal to the weights of the corresponding connections (usually a real number). 
</text>

<equation>
a_{ij} = 
\left \{
\begin{matrix}
 w(v_i,v_j) &amp; if &amp; (v_i, v_j) \in E(G)\\ 
 0 &amp; if &amp; i=j \\
 \infty &amp; if &amp; (v_i,v_j) \notin E(G)
\end{matrix}
\right.
</equation>


<text>
All elements along the main diagonal of <eqn>A</eqn> are 0 if we do not allow loops (i.e. a vertex cannot be adjacent to itself). ++ Undefined values (-) for SNA, 1 or 2 when loops are allowed (usually 2 for undirected graphs)...

N: for a network with no self-edges such as this one the diagonal matrix elements are all zero, and second that it is symmetric, since if there is an edge between i and j then there is an edge between j and i.Self-edges are a little more complicated. A single self-edge from vertex i to itself is represented by setting the corresponding diagonal element Aii of the matrix equal to 2. Why 2 and not 1? Essentially it is because every self-edge from i to i has two ends, both of which are connected to vertex i. We will find that many of our mathematical results concerning the adjacency matrix work equally well for networks with and without self-edges, but only if we are careful to count both ends of every edge, including the self-edges, by making the diagonal matrix elements equal to 2 rather than 1... non-self-edges appear twice in the adjacency matrix — an edge from i to j means that both Aij and Aji are 1. To count edges equally, self-edges should also appear twice, and since there is only one diagonal matrix element Aii , we need to record both appearances there

... self-edges in a directed network are represented by setting the corresponding diagonal element of the adjacency matrix to 1, not 2 as in the undirected case (one undirected edge = two directed edges)
</text>

<text>
N. It is also possible to represent multiedges and self-edges using an adjacency matrix. A multiedge is represented by setting the corresponding matrix element Aij equal to the multiplicity of the edge. For example, a double edge between vertices i and j is represented by Aij = Aji = 2. One can also have multiple self-edges (or “multi-self-edges” perhaps). Such edges are represented by setting the corresponding diagonal element of the adjacency matrix equal to twice the multiplicity of the edge.
</text>

<text>
N: it is possible to create a network with multiedges that has the exact same adjacency matrix than a weighted network, by simply choosing the multiplicities of the multiedges equal to the corresponding weights. 
</text>



<text>
N: CONNECTED COMPONENTS the adjacency matrix of a network with more than one component can be written in block diagonal form, meaning that the non-zero elements of the matrix are confined to square blocks along the diagonal of the matrix, with all other elements being zero

Note: depending on the labeling, it might not be evident whether the graph is connected or not (looking for a suitable order would require much more effort than needed, since linear-time algorithms exist for detecting the graph connected components).
</text>

<text>
N: DAG: The adjacency matrix of an acyclic directed network has interesting properties. Suppose we construct an ordering of the vertices of an acyclic network as described above, so that all edges point in one direction, and suppose we then label the vertices in that order. Then there can be an edge from vertex j to vertex i only if j > i. Put another way, the adjacency matrix A (whose element Aij records the presence of an edge from j to i) has all its non-zero elements above the diagonal—it is upper triangular...

... for every acyclic directed network there exists at least one labeling of the vertices such that the adjacency matrix will be strictly upper triangular (i.e. triangular matrices with zeros on the diagonal are called strictly triangular, since loops are not permitted)
</text>


<text>
Matrix permutations: simultaneous rearrangements of rows and columns that do not change information about adjacency
+ Relabeling rows and columns simultaneously
+ ISOMORPHISM: There exists a unique adjacency matrix for each isomorphism class of graphs (up to permuting rows and columns), and it is not the adjacency matrix of any other isomorphism class of graphs... 
</text>


<text>
Several additional observations can be made about adjacency matrices:
</text>

<list>

<item>
The adjacency matrix <eqn>A</eqn> is a symmetric matrix for undirected graphs, since <eqn>a_{ij} = a_{ji}</eqn> for such graphs, but it certainly might be asymmetric for directed graphs.
</item>

<item>
We can obtain the degree of the i-th node of an undirected graph just by adding the entries in row i (or, alternatively, in column i).
</item>

<item>
Similarly, the sum of the entries in row i gives us the out-degree of the ith node in a directed graph, while the sum of the entries in column i gives us its in-degree.
</item>

<item>
When <eqn>a_{ij} = 1</eqn>, the graph contains the edge <eqn>v_iv_j</eqn> and there is a path from <eqn>v_i</eqn> to <eqn>v_j</eqn> of length 1.
</item>

</list>

<text>
This last observation can be exploited to determine whether the graph contains a walk from <eqn>v_i</eqn> to <eqn>v_j</eqn> of length <eqn>k</eqn> for any arbitrary positive integer <eqn>k</eqn>. In fact, the number of different walks of length <eqn>k</eqn> from <eqn>v_i</eqn> to <eqn>v_j</eqn> is given by the <eqn>(i,j)</eqn> entry in the matrix <eqn>A^k</eqn>.
</text>

<text>
Let <eqn>a_{ij}^{(k)}</eqn> denote the <eqn>(i,j)</eqn> entry in the matrix <eqn>A^k</eqn>. We can obtain the following data just by multiplying the adjacency matrix by itself:
</text>

<list>

<item>
The degree of a node: <eqn>d_i = deg(v_i) = a_{ii}^{(2)}</eqn>. Note: k_i (physicists)
</item>

<item>
The size of the network: <eqn>m = \frac{1}{2} \sum d_i = \frac{1}{2} \sum a_{ii}^{(2)} =  \frac{1}{2} \sum a_{ij}</eqn>. Note: k_i (physicists)
</item>

<item>
The number of triangles in G than contain a given node: <eqn>triangles(v_i) = a_{ii}^{(3)} / 2</eqn>.
</item>

<item>
The total number <eqn>C_r</eqn> of cycles of length r anywhere in a network is the sum of <eqn>a_{ii}^{(r)}</eqn> over all possible starting points i, i.e. <eqn>C_r = \sum_i a_{ii}^{(r)} / (2*r) = Tr A^r / (2*r)</eqn>. It should be noted that the sum counts loops consisting of the same vertices in the same order but with different starting points and in both directions, so it must be divided by <eqn>2*r</eqn>. However, this expression still misses the propoer count for paths consisting of the same subcycle repeated several times.
</item>

</list>

<text>
Distance...
</text>

<equation>
d(i,j) = min_k \{ A_{ij}^k &gt; 0 \}
</equation>


<text>
The path/distance matrix:

a.k.a. path matrix (entries equal to the path length separating nodes, or zero, if no path exists)

L: Path matrix P(G) stores the number of hops along the direct path between all node
pairs in a graph; that is, P(G) enumerates the lengths of shortest paths among all
node pairs. If the graph is undirected, then P(G) is symmetric. Also, as with the adjacency
matrix, if no link exists between a node pair, the corresponding element in
P(G) is zero. The diagonal elements of P(G) are zero because we eliminate loops
from consideration, as well as duplicate links.

L: Let D be the size of the longest path—the diameter of G.  Then, P(G) = min_{k=1..D} \{k A^k(G)\}. Powers of adjacency matrix A also contain cycles of length k along the diagonal of Ak. Here, we ignore cycles, so the diagonal elements are set to zero after each multiplication.
</text>


<text>
Graph reachability...
</text>

<equation>
A^\Sigma = A + A^2+ A^3 + ... + A^{n-1}
</equation>


<text>
++ Counting the number of paths of length k by matrix multiplication: A^k (includes non-simple paths), e.g. divide-and-conquer algorithm @ Skiena 425 [Karatsuba KO63], fast multiplication algorithms @ Skiena 403 [Strassen 69][Coppersmith 90][CKSU05]
</text>

<figure>
  <tag>fig-bowtie</tag>
  <image scale="25" file="image/graphs/bowtie"/>
  <title>The bowtie graph.</title>
</figure>

<text>
Any structural property of a network can be expressed in terms of its adjacency matrix, even though it is not practical to perform numerical computations on adjacency matrices for large networks, since such computations would require huge amounts of memory. Moreover, most real-world adjacency matrices are sparse, hence we would waste a lot of time dealing with their zero entries.
</text>

<text>
For instance, consider the bowtie graph in Figure <ref>fig-bowtie</ref> and the powers of its adjacency matrix:
</text>

<equation>
A(G_{bowtie}) =
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 
\end{bmatrix}
</equation>

<equation>
A^2(G_{bowtie}) =
\begin{bmatrix}
2 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 2 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 3 &amp; 0 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 3 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 2
\end{bmatrix}
</equation>

<equation>
A^3(G_{bowtie}) =
\begin{bmatrix}
2 &amp; 3 &amp; 4 &amp; 1 &amp; 1 &amp; 1 \\
3 &amp; 2 &amp; 4 &amp; 1 &amp; 1 &amp; 1 \\
4 &amp; 4 &amp; 2 &amp; 5 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 5 &amp; 2 &amp; 4 &amp; 4 \\
1 &amp; 1 &amp; 1 &amp; 4 &amp; 2 &amp; 3 \\
1 &amp; 1 &amp; 1 &amp; 4 &amp; 3 &amp; 2
\end{bmatrix}
</equation>

<text>
Nodes <eqn>c</eqn> and <eqn>d</eqn> have degree 3, while the remaining nodes have degree 2, as can be seen in <eqn>A^2</eqn>. Observing <eqn>A^3</eqn>, we can conclude that every node in the graph is part of a single triangle and also that all the nodes in the graph are connected by paths whose length is at most 3, since all entries in <eqn>A^3</eqn> are distinct from zero, which indicates that walks of length 3 exist for every pair of nodes in the graph.
</text>

<note>
<text>
Note: The adjacency matrix is also known as the <term>sociomatrix</term> in social network analysis.

+ Undefined values at the diagonal (-)

+ Values of the ties for signed graphs and valued graphs

+ super-sociomatrix (r sociomatrices) for representing multiple relations
</text>
</note>

<text>
The spectral decomposition of the adjacency matrix also provides valuable insight into the nature of a graph. The <term>spectral radius</term> <eqn>\rho(G)</eqn> is computed from the adjacency matrix as its the largest non-trivial (i.e. non-zero) eigenvalue. The largest eigenvalue of the adjacency matrix, often denoted by <eqn>\kappa_1</eqn>, is never below the average degree of the network <eqn>\langle d \rangle = 2m / n</eqn>, nor below the square root of the largest degree <eqn>\Delta</eqn>. Spectral eigenvalues are also called <term>characteristic eigenvalues</term> because they characterize the topology of a graph in succinct terms (in fact, they are completely determined by the graph degree sequence) and they can be useful when analyzing the dynamic behavior of networks (e.g. the spectral radius can determine the persistence of an infection).
</text>

</document>




<document>
<tag>graph-theory-matrix-incidence</tag>
<title>The incidence matrix</title>

<text>
Alternatively, we can describe a graph by means of an edge incidence matrix. The edge incidence matrix of a network with <eqn>n</eqn> nodes and <eqn>m</eqn> links is an <eqn>m \times n</eqn> matrix <eqn>B</eqn> with elements
</text>

<equation>
b_{ij} = 
\left \{
\begin{matrix}
 +1 &amp; \text{ if the head of edge } i \text{ is attached to vertex } j\\ 
 -1 &amp; \text{ if the tail of edge } i \text{ is attached to vertex } j\\
 0  &amp; \text{ otherwise}
\end{matrix}
\right.
</equation>

<text>
The sum <eqn>\sum_k b_{ki}b_{kj}</eqn> will be -1 if there is an edge from vertex i to vertex j and zero otherwise.
When i=j, this sum becomes <eqn>\sum_k b_{ki}^2</eqn> and returns the degree of the ith vertex <eqn>d_i</eqn>.
</text>

<text>
The edge incidence matrix for the bowtie graph is
</text>

<equation>
B(G_{bowtie}) = 
\begin{bmatrix}
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\
\end{bmatrix}
</equation>

<text>
++ BIPARTITE / MULTIGRAPHS: The biadjacency matrix for a bipartite network is a rectangular matrix that corresponds to the incidence matrix. If n is the number of people or other participants in the network and g is the number of groups, then the incidence matrix B is a g × n matrix

...

N: Although a bipartite network may give the most complete representation of a particular network it is often convenient to work with direct connections between vertices of just one type. We can use the bipartite network to infer such connections, creating a one-mode projection from the two-mode bipartite form. As an example, consider again the case of the films and actors. We can perform a projection onto the actors alone by constructing the n-vertex network in which the vertices represent actors and two actors are connected by an edge if they have appeared together in a film. The corresponding one-mode projection onto the films would be the g-vertex network where the vertices represent films and two films are connected if they share a common actor. 

... 
When we form a one-mode projection each group in the bipartite network results in a cluster of vertices in the one-mode projection that are all connected to each other—a "clique" in graph theoretical terms.
...
The one-mode projection is widely employed, but its construction discards a lot of the information present in the structure of the original bipartite network and hence it is, in a sense, a less powerful representation of our data. For example, the projection loses any information about how many groups two vertices share in common... We can capture information of this kind in our projection by making the projection weighted, giving each edge between two vertices in the projected network a weight equal to the number of common groups the vertices share. This weighted network still does not capture all the information in the bipartite original—it doesn’t record the number of groups or the exact membership of each group for instance—but it is an improvement on the unweighted version and is quite widely used.

Mathematically the projection can be written in terms of the incidence matrix B as follows. The product BkiBkj will be 1 if and only if i and j both belong to the same group k in the bipartite network. Thus, the total number Pij of groups to which both i and j belong is Pij = sum... P = B Bt ?
...
Its off-diagonal elements are equal to the weights in that network, the number of common groups shared by each vertex pair
...
Pii is equal to the number of groups to which vertex i belongs.
...
to derive the adjacency matrix of the weighted one-mode projection, we would calculate the matrix P = BTB and set the diagonal elements equal to zero. And to derive the adjacency matrix of the unweighted projection, we would take the adjacency matrix of the weighted version and replace every non-zero matrix element with a 1

to derive the adjacency matrix of the weighted one-mode projection, we would calculate the matrix P = BTB and set the diagonal elements equal to zero. And to derive the adjacency matrix of the unweighted projection, we would take the adjacency matrix of the weighted version and replace every non-zero matrix element with a 1
...
The other one-mode projection, onto the groups, can be represented by a g × g matrix P' = BBT, whose off-diagonal element  gives the number of common members of groups i and j, and whose diagonal element  gives the number of members of group i.
</text>

</document>



<document>
<tag>graph-theory-matrix-connection</tag>
<title>The connection matrix</title>

<text>
In multigraphs, each entry in the connection matrix represents the number of links connecting node i to node j. Formally, <eqn>C(G) = [c_{ij}]</eqn>, where
</text>

<equation>
c_{ij} = 
\left \{
\begin{matrix}
 k_{ij} &amp; if &amp; v_iv_j \in E(G)\\ 
 0 &amp; if &amp; v_iv_j \notin E(G)
\end{matrix}
\right.
</equation>

<text>
and <eqn>k_{ij}</eqn> is the number of links connecting <eqn>v_{i}</eqn> to <eqn>v_{j}</eqn>.
</text>

<text>
For simple graphs, it is clear that <eqn>C(G) = A(G)</eqn>. Hoewever, the connection matrix and the adjacency matrix are different for multigraphs and pseudographs, since parallel edges and loops are not reflected on adjacency matrices. An adjacency matrix contains a 1 in its (i,j) entry whenever a link connect node i to node j, but parallel edges (i.e. duplicate links connecting the same pair of  nodes) are ignored in the adjacency matrix, not so in the connection matrix.
</text>

</document>



<document>
<tag>graph-theory-matrix-degree</tag>
<title>The degree matrix</title>

<text>
Let G be a graph with n nodes. The degree matrix of the graph G is the <eqn>n \times n</eqn> matrix <eqn>D(G) = [d_{ij}]</eqn> where
</text>

<equation>
d_{ij} = 
\left \{
\begin{matrix}
 d_i &amp; if &amp; i = j \\ 
 0   &amp; if &amp; i \neq j
\end{matrix}
\right.
</equation>

<text>
where <eqn>d_i = deg(v_i)</eqn>.
</text>


<text>
The degree matrix of the bowtie network is, then,
</text>

<equation>
D(G_{bowtie}) = 
\begin{bmatrix}
 2 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 \\
 0 &amp;  2 &amp;  0 &amp;  0 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp;  3 &amp;  0 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp;  0 &amp;  3 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp;  0 &amp;  0 &amp;  2 &amp;  0 \\
 0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  2 
\end{bmatrix}
</equation>


</document>




<document>
<tag>graph-theory-laplacian</tag>
<title>The Laplacian matrix</title>

<text>
The graph <term>Laplacian</term> is formed by inserting the degree of the nodes into the diagonal of the adjacency matrix, i.e. it combines the adjacency information in the adjacency matrix with node degree information from the degree matrix. The de-facto standard definition of the graph Laplacian has become
</text>

<equation>
L(G) = D(G) - A(G)
</equation>

<text>
with positive values along the diagonal representing node degrees and non-positive values elsewhere; i.e. -1 at its (i,j)-entry if there is an edge connecting <eqn>v_i</eqn> and <eqn>v_j</eqn>. Alternatively, the graph Laplacian can be written as:
</text>

<equation>
l_{ij} = \delta_{ij}d_{i} - a_{ij}
</equation>

<text>
where <eqn>\delta_{ij}</eqn> is the Kronecker delta, which is 1 if <eqn>i=j</eqn> and 0 otherwise.
</text>

<text>
The Laplacian matrix is designed so that the sum of its row elements is always zero. When the matrix is symmetric, as in undirected graphs, the sum of its columns is also zero. This fact is important, for example, when using the graph Laplacian to study the stability of networks.
</text>


<text>
The Laplacian matrix of the previous bowtie network is, therefore,
</text>

<equation>
L(G_{bowtie}) = 
\begin{bmatrix}
 2 &amp; -1 &amp; -1 &amp;  0 &amp;  0 &amp;  0 \\
-1 &amp;  2 &amp; -1 &amp;  0 &amp;  0 &amp;  0 \\
-1 &amp; -1 &amp;  3 &amp; -1 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp; -1 &amp;  3 &amp; -1 &amp; -1 \\
 0 &amp;  0 &amp;  0 &amp; -1 &amp;  2 &amp; -1 \\
 0 &amp;  0 &amp;  0 &amp; -1 &amp; -1 &amp;  2 
\end{bmatrix}
</equation>

<text>
The Laplacian matrix can also be expressed in terms of the edge incidence matrix:
</text>

<equation>
L = B^t B
</equation>

<text>
since <eqn>l_{ij} = \sum_k b_{ki}b_{kj}</eqn>.
</text>

<text>
The name of the Laplacian matrix comes from the Laplacian operator <eqn>\nabla^2</eqn> that appears on the diffusion equation for a gas, which is replaced by the Laplacian matrix when we model a diffusion process on a network. In this diffusion process, we assume that we have an amount <eqn>\psi_i</eqn> of some kind of commodity at each node and the commodity moves along the edges, flowing from a vertex <eqn>j</eqn> to an adjacent one <eqn>i</eqn>, at a rate given by <eqn>C(\psi_j-\psi_i)</eqn>, where <eqn>C</eqn> is the diffusion constant. Then, from the system of equations given by 
</text>

<equation>
\frac{d\psi_i}{dt} = C \sum_j a_{ij} (\psi_j-\psi_i)
</equation>

<text>
we can obtain the following equation in matrix form:
</text>

<equation>
\frac{d\psi}{dt} + C L \psi = 0
</equation>

<text>
This diffusion equation can be solved by writing the vector <eqn>\psi</eqn> as a linear combination of the eigenvectors <eqn>\vec{v_i}</eqn> of the Laplacian <cite>Newman 2010</cite>, i.e. <eqn>L\vec{v_i} = \lambda_i \vec{v_i}</eqn> where <eqn>\lambda_i</eqn> is the eigenvalue corresponding to the eigenvector <eqn>\vec{v_i}</eqn>. We obtain
</text>

<equation>
\psi(t) = \sum_i a_i(t) \vec{v_i}
</equation>

<equation>
a_i(t) = a_i(0) e^{-C \lambda_i t}
</equation>

<text>
Given the initial conditions of the network, specified by <eqn>a_i(0)</eqn>, we can solve for any later time. Since the Laplacian is a symmetric matrix for undirected networks, it has real eigenvalues. Moreover, all its eigenvalues are non-negative, since they can be expressed as the inner product of a real vector <eqn>B \vec{v_i}</eqn> with itself. This means that the diffusion solution contains only decaying exponentials or constants (for <eqn>\lambda_1 = 0</eqn>), so the process tends to an equilibrium and does not diverge (a reasonable solution if we take into account that the existing amounts <eqn>\psi_i</eqn> are finite from the start).
</text>

<!-- Spectral gap -->

<text>
Let us suppose that a network is divided into <eqn>c</eqn> different components. Then, if we order the vertices so that the first <eqn>n_1</eqn> correspond to the first component, the next <eqn>n_2</eqn> to the second component, and so on, the network Laplacian will be block diagonal. In fact, each block in the Laplacian will be the Laplacian of the corresponding component.
</text>

<text>
Taking into account the definition of the Laplacian as <eqn>l_{ij} = \delta_{ij}d_{i} - a_{ij}</eqn>, when we multiply the vector <eqn>\vec{1}</eqn>, made of ones, by the Laplacian, the ith element of the result will be
</text>

<equation>
\sum_j l_{ij} \times 1 = \sum_j ( \delta_{ij}d_{i} - a_{ij} ) = d_{i} - \sum_j a_{ij} = d_{i} - d_{i} = 0
</equation>

<text>
That is, the vector <eqn>\vec{1}</eqn> is an eigenvector of the Laplacian with eigenvalue 0. If we return to our disconnected network, we can easily obtain <eqn>c</eqn> eigenvectors with eigenvalue zero: the vectors with ones in the positions corresponding to vertices in a single component and zeros elsewhere. Actually, the number of zero eigenvalues is always exactly equal to the number of connected components. As a corollary, we can assert that the network is connected if and only if the second eigenvalue of the network Laplacian <eqn>\lambda_2</eqn> is non-zero. The second eigenvalue of the network Laplacian is called the <term>algebraic connectivity</term> of the network and it is also known as its <term>spectral gap</term> <eqn>\sigma(G)</eqn>.
</text>


<text>
Apart from diffusion processes, which model epidemics, the spread of contagions, rumors, ideas, and group consensus, as well as the spread of chaos throughout a graph, the graph Laplacian also appears in the study of random walks on networks, network connectivity, graph parititioning, and network stability (or the lack of it, which can often be explained by the spectral gap).
</text>

<comment>

<text>
Some authors resort to a normalized Laplacian matrix when they want all elements of L to be less than one. This normalized version is usually defined so that the resulting matrix has ones along its diagonal. Rather than using the Boolean values of the adjacency matrix, adjacency is indicated by
</text>

<equation>
l_{ij} = 
\left \{
\begin{matrix}
 \frac{-1}{\sqrt{d_i d_j}} &amp; if &amp; v_iv_j \in E(G) \\ 
 0        &amp; if &amp; v_iv_j \notin E(G) 
\end{matrix}
\right.
</equation>

<text>
The expression above is the result of defining the Laplacian as <eqn>L = I - D^{-1/2}AD^{-1/2}</eqn>, where <eqn>I</eqn> is the identity matrix, a square matrix with ones on the main diagonal and zeros elsewhere. The Laplacian sometimes is defined as <eqn>L = D^{-1}A - I</eqn>, but none of these alternative definitions yield a matrix whose rows and columns that sum to zero (a useful property when studying network synchronization). Henceforth, we will assume that <eqn>L = D - A</eqn>.
</text>

</comment>

</document>

</document>

<?xml version="1.0"  encoding="ISO-8859-1" ?> 
<!DOCTYPE sys-ents [ <!ENTITY bibliography SYSTEM "bibliography.xml"> ]> 
<?xml-stylesheet type="text/xsl" href="../book.xsl"?>

<!-- Centrality -->

<document>
&bibliography;
<tag>centrality</tag>
<title>Centrality</title>

<text>
Local centrality measures let us infer the potential influence of individual nodes or links within a network and quantify their centrality with respect to the network structure (and information flow therein). In other words, centrality measures try to highlight the most influential nodes within a network, either because their loss might prove to be disruptive for the rest of the network or just because they play key roles within the communication patterns that take place on the network.
</text>

<text>
L: Power. The power of a node is proportional to its degree (number of links connecting
it to the network) influence (link values); and betweenness or closeness;
the power of a network is proportional to the number and strength of
its nodes and links. For example, Metcalf's law states that the power of a
network is proportional to the square of the number of nodes it contains
[e.g., the maximum number of links that a network with n nodes can contain
is n(n2-1)/2, which is approximately n2]. The influence a person exerts on a
group is proportional to the position, number, and power of colleagues the
person has within the group, such as the person’s connectivity. The power of
a corporation, within an industry or market, is proportional to the number
of customers (links) that it has, or its intermediary position within the
industry. Power is a subtle but important organizing principle in most networks,
but it is often called something else, such as influence, signal strength,
or infection rate.
</text>

<text>
The use of a particular metric to characterize the centrality of a node within a given network makes assumptions on the nature of the information flow or the dynamic processes on the network <cite>Borgatti 2005</cite>.
</text>


<document>
<tag>centrality-degree</tag>
<title>Node degree</title>

<text>
Node degree is the simplest indicator of the node importance within the network. As a matter of fact, node degree, or strength in weighted networks, is a simple measure of direct interaction. The balance of in-degree and out-degree might also indicate the role of the node within the network (e.g. whether it primarity sends or receives information).
</text>

<text>
Node degree is highly informative in networks where a small fraction of nodes collect the vast majority of links (a.k.a. scale-free networks). In such networks, high-degree nodes (often called hubs) are essential for maintaining the network connectivity and targeted attacks might be fatal for the network to continue its operation. Just think of major airports and the disruptions they cause on the air traffic when they have to be closed.
</text>

<text>
Degree centrality for undirected graphs:
</text>

<equation>
C_{degree}(i) = \frac{degree(i)}{n-1}
</equation>

<text>
Degree centrality for undirected graphs:
</text>

<equation>
C'_{degree}(i) = \frac{degree_{out}(i)}{n-1}
</equation>

<text>
Value within <eqn>[0,1]</eqn>.
</text>


</document>


<document>
<tag>centrality-closeness</tag>
<title>Closeness</title>

<text>
Many centrality metrics are based on shortest paths. The idea behind them is that a node is central to the network if it has some control over the most efficient routes in the flow of information within the network. This potential control, obviously, comes from the node participation in many of the network shortest paths <cite>Freeman 1978</cite>.
</text>

<text>
The closeness centrality of a given node is the inverse of the average path length between that node and the other nodes in the network.
</text>

<equation>
C_{closeness}(i) = \frac{ n-1 }{ \sum_{j=1}^{n} distance(i,j)}
</equation>

<text>
Value within <eqn>[0,1]</eqn>.
</text>


<text>
A node with a high closeness centrality lies close to the rest of the nodes in the network and, since it can reach them through short paths, it can exert a stronger influence on them than other nodes with a lower closeness centrality.
</text>

<text>
L: Closeness—as defined here—is not a perfect measure of an intermediary’s power
over others. Consider the case of a symmetric graph. It
is highly likely that several shortest paths exist between two arbitrarily chosen source
and destination nodes.
</text>

</document>


<document>
<tag>centrality-betweenness</tag>
<title>Betweenness</title>

<text>
As it happened with closeness, betweenness is also based on the network shortest paths.
</text>

<text>
IDEA: If non-adjacent nodes j and k want to interact and node i is on the path between them, then i may have some control over their interactions.
</text>

<text>
The betweenness centrality of a given node is degined as the fraction of all the shortest paths within the network that go through the node.
</text>

<text>
Let <eqn>p_{jk}</eqn> be the number of shortest paths between nodes <eqn>j</eqn> and <eqn>k</eqn> and <eqn>p_{jk}(i)</eqn> the number of shortest paths between nodes <eqn>j</eqn> and <eqn>k</eqn> that pass through <eqn>i</eqn>.
</text>

<text>
Betweenness centrality for undirected graphs:
</text>

<equation>
betweenness(i) = \sum_{j&lt;k} \frac{ p_{jk}(i) }{ p_{jk} }
</equation>


<text>
<eqn>betweenness(i)</eqn> is between <eqn>0</eqn>, when <eqn>i</eqn> appears in no shortest path between any pair <eqn>(j,k)</eqn>, and <eqn>(n-1)(n-2)/2</eqn>, which is the number of pairs not including <eqn>i</eqn>.
</text>

<text>
If we want betweenness to be between 0 and 1, we normalize:
</text>

<equation>
C_{betweenness}(i) = \frac { 2 \sum_{j&lt;k} \frac{ p_{jk}(i) }{ p_{jk} } } { (n-1)(n-2) }
</equation>


<text>
Betweenness centrality for directed graphs:
</text>

<equation>
C'_{betweenness}(i) = \frac { \sum_{j \neq k} \frac{ p_{jk}(i) }{ p_{jk} } } { (n-1)(n-2) }
</equation>

<text>
Since now there are <eqn>(n-1)(n-2)</eqn> pairs if we consider that a path from <eqn>j</eqn> and <eqn>k</eqn> is different than a path from <eqn>k</eqn> to <eqn>j</eqn>.
</text>

<text>
A node with a high betweenness centrality can control information because it lies at the intersection of many short paths (e.g. key midfield player in soccer).
</text>

<text>
++ <cite>Barthelemy 2004</cite>
</text>

<text>
The betweenness centrality is also known as load by physicists, since it is related to the total number of data packets passing through a node when every pair of nodes sends and receives packets through the shortest path connecting the pair.
</text>

<text>
Unlike the closeness measure, betweenness can also be computed for non-connected graphs.
</text>

<text>
For computing the number of shortest paths from every other node u to every other node v running through node w, we must trace the <eqn>n^2</eqn> shortest paths traversed from every node to every other node, count the number of paths running through the nodes along each path, and then sum the counts for each node...
</text>


<text>
It should be noted that both closeness and betweenness only consider what happens on the shortest paths between nodes, ignoring the network traffic that might occur on longer paths that also contribute to global network communication patterns. Moreover, betweenness assumes that flow along the shortest path is unaffected by bifurcations and confluences along the path. Matrix-based centrality metric take them into account.
</text>

<text>
++ ALGORITHMS
http://www.cs.ucc.ie/~rb4/resources/betweennessFull_studentThesis.pdf

All algorithms have in common that they need to solve the SSSP problem resulting in a shortest
path tree with root s on forward search (or root t on backward search). For unweighted graphs
this is possible with breath ?rst search (BFS), for weighted graphs Dijkstra’s algorithm is used.

The fastest algorithm up to date to calculate exact general betweenness centrality is Brandes' exact algorithm. 
It requires O(nm+n^2log(n)) time for a weighted graph where n = |V |, m = |E|. It solves n SSSP (Single Source Shortest Path) 
problems with Dijkstra's algorithm. Then it adds counter values from leaves to the top.
[
Ulrik Brandes. 
A faster algorithm for betweenness centrality. 
Journal of Mathematical Sociology, 25(2):163–177, 2001.
DOI:10.1080/0022250X.2001.9990249
]


Brandes and Pich introduced a unbiased technique to approximate general betweenness by choosing only k \ll n pivots as source for the SSSP algorithm. They turned their attention especially to the pivot selection method. As their results show no significant advantage of specialized methods over random pivot selection no other selection method was used by us. Another advantage of random selection is its performance.
[
Ulrik Brandes, Christian Pich: 
Centrality Estimation in Large Networks. 
International Journal of Bifurcation and Chaos 17(7): 2303-2318 (2007)
http://dx.doi.org/10.1142/S0218127407018403
]

Bader and Madduri [2] introduced parallel algorithms to calculate exact general betweenness centrality. Their algorithms can reduce execution time by some multipliers but need many CPU cores and much RAM. This is useful if exact general betweenness centrality values are necessary and resources are available. But if good estimations are suficient or resources are too expensive, approximation algorithms should be preferred.
[
David A. Bader and Kamesh Madduri. 
Parallel algorithms for evaluating centrality indices in real-world networks. 
ICPP '06 Proceedings of the 2006 International Conference on Parallel Processing
In ICPP, pages 539–550. IEEE Computer Society, 2006
ISBN:0-7695-2636-5
DOI 10.1109/ICPP.2006.57
]


++
Approximating betweenness centrality
Authors:	
David A. Bader	College of Computing, Georgia Institute of Technology
Shiva Kintali	College of Computing, Georgia Institute of Technology
Kamesh Madduri	College of Computing, Georgia Institute of Technology
Milena Mihail	
Published in:
WAW'07 Proceedings of the 5th international conference on Algorithms and models for the web-graph
Springer-Verlag Berlin, Heidelberg ©2007 
ISBN:3-540-77003-8 978-3-540-77003-9
ABSTRACT: Betweenness is a centrality measure based on shortest paths, widely used in complex network analysis. It is computationally-expensive to exactly determine betweenness; currently the fastest-known algorithm by Brandes requires O(nm) time for unweighted graphs and O(nm + n2 log n) time for weighted graphs, where n is the number of vertices and m is the number of edges in the network. These are also the worstcase time bounds for computing the betweenness score of a single vertex. In this paper, we present a novel approximation algorithm for computing betweenness centrality of a given vertex, for both weighted and unweighted graphs. Our approximation algorithm is based on an adaptive sampling technique that significantly reduces the number of single-source shortest path computations for vertices with high centrality. We conduct an extensive experimental study on real-world graph instances, and observe that our random sampling algorithm gives very good betweenness approximations for biological networks, road networks and web crawls.

++
Performance analysis of an algorithm for computation of betweenness centrality
Authors:	
Shivam Bhardwaj	Department of Electronics and Computer Engineering, Indian Institute of Techology Roorkee, Roorkee, India
Rajdeep Niyogi	Department of Electronics and Computer Engineering, Indian Institute of Techology Roorkee, Roorkee, India
Alfredo Milani	Department of Mathematics and Computer Science, University of Perugia, Perugia, Italy
Published in:
ICCSA'11 Proceedings of the 2011 international conference on Computational science and Its applications - Volume Part V
Springer-Verlag Berlin, Heidelberg ©2011 
ISBN: 978-3-642-21933-7
ABSTRACT: In social network analysis, graph-theoretic perceptions are used to realize and explain social experience. Centrality indices are essential in the analysis of social networks, but are costly to compute. An efficient algorithm for the computation of betweenness centrality is given by Brandes that has time complexity O(nm + n2logn) and O(n + m) space complexity, where n, m are the number of vertices and edges in a graph, respectively. Some social network graphs are invariably huge and dense. Moreover, size of memory is rapidly increasing and the cost of memory is decreasing day by day. Under these circumstances, we investigate how the computation of centrality measures can be done efficiently when space is not very significant. In this paper, we introduce a time efficient and scalable algorithm for the accurate computation of betweenness centrality. We have made a thorough analysis of our algorithm visà-vis Brandes' algorithm. Experimental results show that our algorithm has a better performance with respect to time, but at the expense of using higher memory. Further performance improvement of our algorithm has been achieved by implementing it on parallel architectures.

++
David A. Bader:
Petascale computing for large-scale graph problems
PPAM'07 Proceedings of the 7th international conference on Parallel processing and applied mathematics
Springer-Verlag Berlin, Heidelberg ©2008 
ISBN:3-540-68105-1 978-3-540-68105-2
PARALLEL PROCESSING AND APPLIED MATHEMATICS
Lecture Notes in Computer Science, 2008, Volume 4967/2008, 166-169, DOI: 10.1007/978-3-540-68111-3_18

ABSTRACT: Graph theoretic problems are representative of fundamental kernels in traditional and emerging computational sciences such as chemistry, biology, and medicine, as well as applications in national security. Yet they pose serious challenges for parallel machines due to non-contiguous, concurrent accesses to global data structures with low degrees of locality. Few parallel graph algorithms outperform their best sequential implementation due to long memory latencies and high synchronization costs. In this talk, we consider several graph theoretic kernels for connectivity and centrality and discuss how the features of petascale architectures will affect algorithm development, ease of programming, performance, and scalability.
</text>

<text>
++ Edge betweenness...
</text>

</document>


<document>
<tag>centrality-participation</tag>
<title>Participation</title>

<text>
When communities are identified within a network, within-module and between-modules connectivity can also provide information about the specific contributions of individual nodes. Participation coefficients measure the diversity of between-modules connections <cite>Guimera and Amaral 2005</cite> <cite>Guimera et al. 2007</cite>.
</text>

<text>
Connector hubs are high-degree nodes that maintain a diverse set of between-modules connections and have a high participation coefficient. Provincial hubs, however, are also high-degree nodes but mostly participate in connections within their community, hence they have a low participation coefficient. Although provincial hubs are unlikely to play a key role in the global network communication patterns, they still play a key role in the maintenance of their communities' cohesion.
</text>

</document>




<document>
<tag>centrality-prestige</tag>
<title>Prestige</title>

<text>
Look at in-links rather than out-links (only for directed graphs)...
</text>

<text>
<b>Degree prestige</b>: A node is prestigious if it receives many in-links (vs. degree centrality).
</text>

<equation>
P'_{degree}(i) = \frac{degree_{in}(i)}{n-1}
</equation>

<text>
<b>Proximity prestige</b>: Generalizes degree prestige by considering non-adjacent nodes (vs. closeness).
</text>

<text>
First, we compute the average distance to <eqn>i</eqn>:
</text>

<equation>
\frac{ \sum_{j \in I_i} distance(j,i) }{ |I_i| }
</equation>

<text>
where <eqn>I_i</eqn> is the influence domain of <eqn>i</eqn>, i.e. the set of nodes that can reach node <eqn>i</eqn>.
</text>

<text>
Then, we normalize by considering the ratio of nodes that can reach <eqn>i</eqn> with respect to their average distance:
</text>

<equation>
P'_{proximity}(i) = \frac { \frac{ |I_i| }{ n-1 } }{ \frac{ \sum_{j \in I_i} distance(j,i) }{ |I_i| } }
</equation>

<text>
<b>Rank prestige</b>, when we consider the prominence of nodes that link to the node whose prestige we are trying to evaluate...
</text>

<equation>
P'_{rank}(i) = A_{1i} P'_{rank}(1) + A_{2i} P'_{rank}(2) + ... + A_{ni} P'_{rank}(n)
</equation>

<text>
where <eqn>A</eqn> is the adjacency matrix (i.e. <eqn>A_{ji}</eqn> is 1 if there is an arc between <eqn>j</eqn> and <eqn>i</eqn>, 0 otherwise).
</text>

<text>
The expression above leads to the following equation in matrix form:
</text>

<equation>
P'_{rank} = A^T P'_{rank}
</equation>

<text>
where <eqn>P'_{rank}</eqn> is a column vector containing all the rank prestige values: <eqn>P_{rank} = ( P_{rank}(1) P_{rank}(2) ... P_{rank}(n) )^T</eqn>.
</text>

<text>
The above matrix equation is the one employed for finding the eigensystem of <eqn>A^T</eqn> and <eqn>P'_{rank}</eqn> is an eigenvector of <eqn>A^T</eqn>. This equation is also at the heart of all the matrix-based centrality measures we will study in the next two sections.
</text>

</document>

<document>
<tag>centrality-matrix</tag>
<title>Matrix-based centrality measures</title>

<text>
++ <cite>Page et al. 1998</cite>
</text>

<text>
IDEA: Since a page can link to many pages, its score should be split among all the pages it points to (different than the rank prestige definition above).
</text>

<equation>
PageRank(i) = \sum_{(j,i) \in E} \frac { PageRank(j) } { degree_{out}(j) }
</equation>

<text>
The above expression leads to a system of n linear equations with n unknowns, which can be stated in matrix form as the characteristic equation of an eigensystem and solved using an iterative algorithm. The solution is an eigenvector with an eigenvalue of 1. When some conditions hold, 1 corresponds to the largest eigenvalue and the PageRank vector is the principal eigenvector, which can be found using power iteration, a well-known technique. In order to meet such conditions, a Markov chain model of the graph is built whose unique stationary probability distribution corresponds to the principal eigenvector with eigenvalue of 1.
</text>

<text>
For the Markov model to have an unique stationary distribution, its stochastic transition matrix must be irreducible and aperiodic. Let us see how it can be derived from the graph adjacency matrix. 
</text>

<text>
1. The entries in each row of a stochastic transition matrix for a finite Markov chain must be non-negative and sum up to 1, which requires all nodes to have, at least, one out-link. Since some nodes might not have out-links, we could remove those pages when performing the initial PageRank computation or add a complete set of outgoings links from each node without out-links to all the nodes in the network (i.e. 1/n transition probability). 
</text>

<text>
2. For the matrix to be irreducible, the graph it represents must be strongly connected.
</text>


<text>
3. A Markov chain is periodic when there exists a directed cycle the chain must traverse.
</text>

<text>
Problems 2 and 3 can be dealt with using a single strategy. Namely, adding a link from each page to every page and giving each link a small transition propability. This augmented transition matrix becomes irreducible (it is strongly connected) and also aperiodic. In the PageRank stochastic model, an out-link is randomly chosen with probability d and we jump to a random page without a link with probability 1-d, which leads to the following equation:
</text>

<equation>
P = \left ( (1-d) \frac{E}{n} + dA^T \right ) P
</equation>

<text>
where <eqn>E=ee^T</eqn> and <eqn>e</eqn> is a column vector of 1's, hence <eqn>E</eqn> is an <eqn>n \times n</eqn> square matrix of ones, and <eqn>A</eqn> is an stochastic matrix derived from the graph adjacency matrix as described in the above discussion.
</text>

<text>
By multiplying by n on both sides, we obtain the PageRank formula
</text>

<equation>
P = (1-d) e + d A^T P
</equation>

<text>
which is equivalent to
</text>

<equation>
P(i) = (1-d)  + d \sum_{(j,i) \in E} \frac { P(j) } { degree_{out}(j) }
</equation>

<text>
where <eqn>d</eqn> is known as the damping factor, a value between 0 and 1, set at 0.85 in <cite>Page et al. 1998</cite>.
</text>

<text>
PageRank values can then be computed using the power iteration method:
</text>

<code>
PageRank = e/n

repeat
  prev = P
  PageRank = (1-d)*e + d*A'*P
until ||PageRank-prev|| &lt; epsilon
</code>

<text>
NOTE: As in the standard Matlab notation, A' indicates the transpose of A.
</text>

<text>
<cite>Brin and Page 1998</cite> reports that the algorithm converges to an acceptable tolerance after just 52 iterations using a 322 million link network. Other advantages include its robustness against fake links, which will come from non-important nodes, and its query independence (it can be precomputed and used in combination with other factors in search engines such as Google).
</text>


<text>
++ <cite>Katz 1953</cite>
</text>

<text>
++ <cite>Bonacich 1972</cite> <cite>Bonacich 2007</cite>: Eigenvector centrality (takes into account interactions of different path lengths and their dispersion, relying on walks rather than shortest paths).
</text>



</document>


<document>
<tag>centrality-hubs</tag>
<title>Hubs and authorities</title>

<text>
Citation analysis: co-citation and bibliographic coupling
</text>

<text>
N: It is sometimes convenient to turn a directed network into an undirected one for the purposes of analysis. Two measures of vertex similarity...

- The cocitation of two vertices i and j in a directed network is the number of vertices that have outgoing edges pointing to both i and j. In the language of citation networks, for instance, the cocitation of two papers is the number of other papers that cite both.

- Bibliographic coupling is similar to cocitation. The bibliographic coupling of two vertices in a directed network is the number of other vertices to which both point. In a citation network, for instance, the bibliographic coupling of two papers i and j is the number of other papers that are cited by both i and j. 
</text>

<text>
<b>Co-citation</b>: When two papers are cited by a third one, they are somehow related even though they do not cite each other. Co-citation is a similarity measure defined as the number of papers that co-cite a given pair of papers:
</text>

<equation>
CC_{ij} = \sum_{k=1}^{n} A_{ki} A_{kj}
</equation>

<text>
<eqn>CC_{ij}</eqn> is the co-citation matrix, which is symmetric.
</text>

<text>
Co-citation network:
N: ... we can define a cocitation network in which there is an edge between i and j if Cij &gt; 0, for i \neq j, i.e., an edge between any two vertices that are cocited in the original directed network. (We enforce the constraint that i \neq j because the cocitation network is conventionally defined to have no self-edges, even though the diagonal elements of the cocitation matrix are in general nonzero—see below.) ... we can also make the cocitation network a weighted network with positive integer weights on the edges equal to the corresponding elements Cij. T... In citation networks of academic papers, for instance, strong cocitation between papers is often a good indicator of papers that deal with related topics—if two papers are often cited together in the same bibliography they probably have something in common. And the more often they are cited together, the more likely it is that they are related.

... The cocitation matrix thus plays a role similar to an adjacency matrix for the cocitation network. There is however one aspect in which the cocitation matrix differs from an adjacency matrix: its diagonal elements. The diagonal elements of the cocitation matrix are equal to  the total number of edges pointing to i—the total number of papers citing i.
</text>

<text>
<b>Bibliographic coupling</b> mirrors co-citation by linking papers that cite the same articles (i.e. when two papers cite a third one, they are also related even though they do not cite each other). Let as define <eqn>BC_{ij}</eqn> as the number of papers that are cited by both <eqn>i</eqn> and <eqn>j</eqn>:
</text>

<equation>
BC_{ij} = \sum_{k=1}^{n} A_{ik} A_{jk}
</equation>

<text>
<eqn>BC_{ij}</eqn> defines the bibliographic coupling matrix, which is also symmetric.
</text>


<text>
N: Bibliographic coupling, like cocitation, can be a useful measure of connection between vertices. In a citation network, for example, if two papers cite many of the same other papers it is often a good indication that they deal with similar subject matter, and the number of common papers cited can be an indicator of how strongly they overlap
</text>

<text>
N: n a citation network, for instance, two papers can only have strong cocitation if they are both well cited and hence strong cocitation is limited to influential papers, review articles, books, and similar highly cited items. Conversely, two papers can only have strong bibliographic coupling if they both cite many others, i.e., if they have large bibliographies. In practice, the sizes of bibliographies vary less than the number of citations papers receive, and hence bibliographic coupling is a more uniform indicator of similarity between papers than cocitation... the cocitation of two papers can change over time as the papers receive new citations, whereas bibliographic coupling is fixed from the moment the papers are published.
</text>

<text>
The HITS algorithm is related to these two citation analysis metrics. HITS stands for Hypertext Induced Topic Search. Unlike PageRank, HITS is query dependent. For each query, HITS expands the list of relevant pages returned by a search engine and ranks those pages according to two criteria: authority ranking and hub ranking.
</text>

<text>
Authorities receive many in-links, whereas hubs contain many out-links. The hubs and authorities found by the HITS algorithm are related to co-citation and bibliographic coupling matrices.
</text>


<text>
++ <cite>Kleinberg 1998</cite> <cite>Kleinberg 1999a</cite> <cite>Kleinberg 1999b</cite>
</text>

<text>
IDEA: A good hub links to many good authorities. Likewise, a good authority is pointed to by many good hubs. This mutual reinforcement is exploited by the HITS algorithm.
</text>

<text>
After expanding the set of pages with those pointed by or pointing to pages in the search engine result set, HITS assigns every page an authority score and a hub score...
</text>


<equation>
authority(i) = \sum_{(j,i) \in E} hub(j)
</equation>

<equation>
hub(i) = \sum_{(i,j) \in E} authority(j)
</equation>

<text>
In matrix form:
</text>

<equation>
a = A^T h
</equation>

<equation>
h = A a
</equation>

<text>
The computation of authority and hub scores is performed using the power iteration method, as happened with PageRank:
</text>

<equation>
a = A^T A a = CC a
</equation>

<equation>
h = A A^T h = BC a
</equation>


<text>
Co-citation, CC, and bibliographic coupling, BC, matrices can be computed beforehand, since they are involved in the iterative computation of hub and authority scores...
</text>

<text>
In pseudocode:
</text>

<code>
authority = e
hub = e

CC = A' * A
BC = A * A'

repeat
  // Previous values
  prevA = authority
  prevH = hub
  // Iteration
  authority = CC * authority
  hub = BC * hub
  // Normalization
  authority = authority / ||authority||
  hub = hub / ||hub||
until (||authority-prevA|| &lt; epsilonA) and (||hub-prevH|| &lt; epsilonH)
</code>



<text>
PROBLEM: For certain graphs, different initializations result in different authority and hub vectors (ref. Farahat et al.: "Authority rankings for HITS, PageRank, and SALSA: Existence, uniqueness, and effect of initialization," SIAM Journal on Scientific Computing 27(4):1181-1201, 2006). This problem is caused by the fact that <eqn>A^T A</eqn> is reducible (ref. Langville et Meyer: "Deeeper inside PageRank", Intenet Mathematics 1(3):335-380, 2004).
</text>

</document>



<document>
<tag>metrics-notes</tag>
<title>Bibliographic notes</title>

<text>
Despite their overlap and partial redundancy, different centrality metrics provide unique information about individual nodes and their neighborhoods, hence each one is suitable for particular applications...
</text>

<text>
++ Studies <cite>Varlamis et al. 2010</cite> <cite>Maiya and Berger-Wolf 2010b</cite> <cite>Rubinov and Sporns 2010</cite>
</text>


</document>


</document>

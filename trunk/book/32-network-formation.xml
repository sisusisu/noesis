<?xml version="1.0"  encoding="ISO-8859-1" ?> 
<!DOCTYPE sys-ents [ <!ENTITY bibliography SYSTEM "bibliography.xml"> ]> 
<?xml-stylesheet type="text/xsl" href="../book.xsl"?>


<document>
&bibliography;
<title>Models of Network Formation</title>


<text>
L: random graphs have random structure, and k-regular graphs have purely deterministic structure. In between these two extremes lie two important classes of graphs: the class of small-world (mostly structured, partly random), and the class of scale-free (mostly random, partly structured) graphs. Each class has its own characteristic property: the Poisson distribution for random graphs, powerlaw distribution for scale-free graphs, high average cluster coefficient for small-world graphs, and zero-entropy value for k-regular graphs.
</text>

<text>Growing random networks ++</text>


<!-- Small worlds -->

<document>
<tag>small-worlds</tag>
<title>Small worlds</title>

<text>
<cite>Pool and Kochen 1978</cite> @ inaugual issue of the Social Networks journal (a draft widely circulated two decades before its publication): the world of social relationships is much smaller than expected given the size of the social network.

i.e. the earliest known theoretical analysis of small-world networks
</text>

<text>
<cite>Travers and Milgram 1969</cite> famous experiments...

+ White identified biases in Milgram's experiment and suggested modifications that lead to an average of seven intermediaries (White, 1970). 
[White, H. C., Search parameters for the small world problem, Soc. Forces 49:259-264 (1970).]

+ Hunter and Shotland modeled the experiment as a Markov process to determine average distances between groups (Hunter, 1974).
[Hunter, J. and R. L. Shotland, Treating data collected by the small world method as a Markov process, Social Forces 52:321-332 (1974).]

Two decades later (Kleinfeld, 2002).
[Kleinfeld, J., Six degrees of separation: Urban myth? Psychol. Today (2002)]
2002 Kleinfeld, Claims Milgram experiments not well founded: small-world social network is an "urban myth"

</text>

<document>
<tag>small-worlds-properties</tag>
<title>Properties of small-world networks</title>

<text>
DEGREE DISTRIBUTION

L: A small-world network ... is a slightly structured and partially random network that is closer to the structured end of the spectrum than to the class of random networks that have no discernable structure or topology.


L: A small-world graph, G(small world), is a graph with relatively small average path
length, and a relatively high cluster coefficient, CC(G). Generally, the average path
length of a small world grows proportional to O(log(n)/log(lambda)), where where lambda is the mean node degree,
and the clustering coefficient tends to be greater than 50%.

The small-world graph has the largest cluster coefficient even though its
degree sequence distribution is very similar to that of a random graph....
The class of small-world graphs is characterized by an unexpectedly large cluster
coefficient when compared to the class of random graphs, but it also has some properties
in common with the class of random graphs. For example, small-world and
random graphs have similar degree distributions and diameters.

The cluster coefficient of a small world can be several orders of magnitude
larger that that of an equivalent random graph of the same size and with an equivalent
number of links.
</text>

<text>
<cite>Kleinberg 2000</cite>, not only surprisingly short paths, but also the remarkable ability of individuals to identify links that lead to those short paths...
</text>

</document>



<document>
<tag>small-worlds-examples</tag>
<title>Small-world networks in the real world</title>

<text>
L: Very sparse networks with small diameter (small worlds) at diverse phenomena such as phase transitions in materials, functionality of biological organisms, and behavior of electrical power grids.
e.g. database of film actors, the electric power grid of the western United States, and the neural network of the nematode worm C. elegans (Caenorhabditis elegans)

L: Sparse small-world networks appear to model human social networks, because humans have limited capacity to know a large number of other humans.

K: Jure Leskovec and Eric Horvitz [273]. They analyzed 30 billion conversations among 240 million active user accounts on Microsoft Instant Messenger (IM): a giant component containing almost all of the nodes, with an estimated average distance of 6.6 and an estimated median of 7 (over a random sample, due to the huge size of the graph)
@SNAP: Largest network we analyzed so far using the library was the Microsoft Instant Messenger network from 2006 with 240 million nodes and 1.3 billion edges. WWW 2008
[Planetary-Scale Views on a Large Instant-Messaging Network by J. Leskovec, E. Horvitz. International World Wide Web Conference (WWW), 2008. ]
extended version @
[Jure Leskovec and Eric Horvitz (June 2007). Planetary-Scale Views on an Instant-Messaging Network. arXiv:0803.0939.]
http://arxiv.org/abs/0803.0939

W: algorithm finds an average degree of separation of 3.43 between two random Twitter users, requiring an average of only 67 requests for information over the Internet to Twitter. A near-optimal solution of length 3.88 can be found by making an average of 13.3 requests.
[Reza Bakhshandeh, Mehdi Samadi, Zohreh Azimifar, Jonathan Schaeffer, "Degrees of Separation in Social Networks", Fourth Annual Symposium on Combinatorial Search, 2011] 
http://www.aaai.org/ocs/index.php/SOCS/SOCS11/paper/view/4031

W: Facebook's data team released two papers in November 2011 which document that amongst all facebook users at the time of research (721 million users with 69 billion friendship links) there is an average distance of 4.74. Probabilistic algorithms were applied on statistical metadata to verify the accuracy of the measurements.[23] It was also found that 99.91% of facebook users were interconnected, forming a large connected component.[24]
- Backstrom, Lars; Boldi, Paolo; Rosa, Marco; Ugander, Johan; Vigna, Sebastiano (2011-11-19). "Four Degrees of Separation". ArXiv. Retrieved 23 November 2011.
- Ugander, Johan; Karrer, Brian; Backstrom, Lars; Marlow, Cameron. "The Anatomy of the Facebook Social Graph". ArXiv. Retrieved 23 November 2011.


Common Examples of Small-World Networks <cite>Lewis 2009</cite>

Graph, n, Small-World Cluster Coefficient, Random Cluster Coefficient
World Wide Web            153,127 0.11 0.00023
Internet                    6,209 0.30 0.00100
Actors in same movie      225,226 0.79 0.00027
Coauthor scientific papers 52,909 0.43 0.00018
Western US power grid       4,941 0.08 0.00200
C. elegans neural network     282 0.28 0.05000
Foodweb (ecological chain)    134 0.22 0.06000

</text>

<text>
<cite>Uzzi et al. 2007</cite>
</text>

<text>
Dorogovtsev, Mendes, Samukhim, Krapivsky, and Redner derived
an exact formula for the power law of a purely scale-free network and showed that
it describes many biological systems (Dorogovtsev, 2000; 2002a; 2002b; 2003).
</text>

<text>
Networks are considered to be small worlds when they have a high clustering coefficient but exhibit a similar path length when compared to random networks with the same number of nodes and links.
</text>

<text>
Small-world-ness measure <cite>Humphries and Gurney 2008</cite>: The small-world index = ratio of the clustering coefficient to the path length after normalizing by the corresponding values for random networks.
</text>


<text>
A different class of small-world networks <cite>Sporns 2006</cite>: modular small-world networks (generated from isolated modules by gradually redistributing connections from within modules to between modules).
</text>


<text>
2001 Yung Taxonomy of applications of small-world theory to: SNA, collaboration, Internet, business, life sciences
[Yung, V. J. An exploration in the small world networks, available as Condensed Matter 0004214 (2000/2001)]
</text>

</document>


<document>
<tag>small-worlds-formation</tag>
<title>Models of small-world network formation</title>

<document>
<tag>formation-watts-strogatz</tag>
<title>Watts-Strogatz model (small-world networks)</title>

<text>
++
<cite>Watts and Strogatz 1998</cite> created a simple model that originates small worlds + discovered that these patterns are present in a broad range of networks. 

Algorithm: initially construct a graph with regular structure. Next, apply rewiring to every link with probability p, such that p*m links are randomized (redirected to a randomly selected node). Parameter p is the rewiring probability, and m is the number of links in the original regular graph.

L: increasing p also increases the randomness of the small world. This means we can produce a network with any desired level of randomness—entropy, if you will—by adjusting rewiring probability p—a low rewiring probability generates a nonrandom structure, and a high probability generates a random structure

L: At a certain rewiring probability called the crossover point (also length scale), the network transitions from mostly structured to mostly random network. Typically, the crossover point is very small—on the order of 2-3%. Watts and Strogatz attached a meaning to the crossover, suggesting that it corresponds to phase transition in materials (the crossover point is also known as the phase transition threshold).

L: Watts and Strogatz: small worlds as networks with relatively short distances (hops) between node pairs chosen at random, even as the size of the network grows. Specifically, the diameter of a network increases as ln(n) while its size increases by O(n), where n is number of nodes.
</text>


</document>

</document>


<document>
<tag>small-worlds-dynamics</tag>
<title>The dynamics of small-world networks</title>


<text>
++ 1999 Walsh: Difficulty of search in small worlds using local properties
[Walsh, T., Search in a small world, IJCAI'99, Proc. 16th Intnatl. Joint Conf. Artificial
Intelligence, Stockholm, Sweden, Morgan Kaufmann Publishers, San Francisco, 1999,
Vol. 2, pp. 1172-1177.]

++ 2000 Kleinberg: Shows O(n) search in small world using "Manhattan distance"
[Kleinberg, J. M., Navigation in a small world, Nature 406:845 (2000).]

L: Kleinberg gives a formal explanation for Milgram's experiment based on
the "Manhattan distance" between source and target nodes. The "Manhattan distance"
is defined as the number of blocks, traversed along streets in Manhattan,
New York, between source and destination intersections. Kleinberg showed that it
takes only O(n) steps to navigate such a small world (Kleinberg, 2002a).
</text>

<text>
Strogatz claimed that the beating of a human's heart, the chirping of crickets, and
other biological systems naturally sync because they are small-worlds (Strogatz,
2003). But today we know that network synchronization has little to do with small-world
topology, and everything to do with the Laplacian of the connection matrix, and
the length of circuits within the network.

ref. Atay networks (Atay, 2006), We examine stability of Atay networks,
which have applications in marketing, as well as understanding the chirping of crickets,
and show that sync is a property of emergent networks that contain triangleshaped
subgraphs. As it turns out, small-world networks have an abundance of
triangular subgraphs! Moreover, a network can be synchronized, by adding a triangular
subgraph to one of its nodes.
</text>

<text>
MORE
</text>

<text>
2000 Marchiori, Latora: Harmonic distance replaces path length: works for disconnected networks
[Marchiori, M. and V. Latora, Harmony in the small-world, Physica A 285(3-4):539-546 (2000).]
</text>

</document>

</document>

<!-- Scale-free networks -->

<document>
<tag>scale-free</tag>
<title>Scale-free networks</title>


<text>
Anthropologists such as Elman Service, when studying cultural evolution, envision chiefdoms being formed when several villages were bound by commerce. The village located at the nexus would naturally become the richest and would gradually grow dominant <cite>Wright 2000</cite>. This <q>rich get richer</q> effect is pervasive in networks...
</text>

<text>
A wide range of real-world networks have been found to exhibit power-law degree distributions: the World Wide Web, citation networks, cellular metabolism networks...
</text>


<document>
<tag>scale-free-properties</tag>
<title>Properties of scale-free networks</title>

<text>
Degree distribution: 

L: Networks whose degree distribution approximates a power law,
<eqn>H(k)=k^{-q}</eqn>, for some power <eqn>q &gt; 1</eqn>. 

L:Such graphs are called scale-free because the power-law distribution has no scale parameter; that is, the variance of a power-law is
infinite, versus the finite variance of most other distributions such as the Gaussian or normal distribution. Power laws are also sometimes called “fat tailed” because they do not decline as k increases as fast as an exponential or normal distribution.

Random graphs more or less distribute links uniformly across n nodes. But... scale-free graphs are lopsided - a vast number of nodes have only one or two links, while a rare few nodes have perhaps hundreds of links... 


scale-free graphs have less entropy than random graphs, but more than small worlds...
The entropy of a scale-free graph is generally lower than the entropy of a random
graph because scale-free networks contain some structure. Scale-free networks are closer to the random end of the "graph structure" spectrum
than to the structured extreme. At one end is the class of structured k-regular graphs
(where entropy equals zero), and the other end is the class of random networks that
have no discernable structure or topology. In between is the class of scale-free networks,
which have some structure, because the degree sequence distribution obeys a power law.

A conjecture: a scale-free graph is more random than structured; a small-world graph is more structured than random
</text>


<text>
A power law implies that the probability of finding a node with a degree that is twice as large as a given number decreases by a constant factor, rather than following an exponential falloff. ++ exponent of the power law distribution.

L: "the probability that a site has k links obeys a power law, which drops off quickly for large k"
... A network that follows a power-law distribution means that it has a
hub, and many other nodes with many fewer links than the average. This lopsided
preference for hubs seemed counter to nature, which typically follows a normal distribution.

L: A scale-free graph has many nodes with very low degree, and one node with very
high degree. Hence, its degree distribution is skewed to the left—toward small degree
values. Because so many nodes are connected to the graph’s hub node, the scale-free
graph also exhibits a small graph diameter—similar to a random graph. It is nearly
one-half the diameter of the small-world graph, and 50% smaller than the diameter
of a random graph. This is a consequence of the high concentration of links attached
to the hub. The unexpectedly large hub degree is a distinguishing property of scalefree
graphs.
</text>

<text>
IDEA: The fluctuations in degree are unbounded, i.e., the standard deviation is bounded only by the finite size of the graph.
</text>


<text>
The <q>scale-free</q> term refers to the fact that nodes in a scale-free network do not have a characteristic scale. You can zoom in on any segment of the distribution and it does not change its shape.

L: scale-free networks... The name came from observing that a function f(x) scales if f(ax) = a*f(x), which is
what a power law does. Therefore, if the degree sequence distribution obeys the power law, h(x) = x ^-q, then it is clear that h(ax) = (ax)^-q = (a ^-q)h(x) = a' h(x).
</text>

</document>



<document>
<tag>scale-free-examples</tag>
<title>Scale-free networks in the real world</title>

<text>
<cite>Clauset et al. 2009</cite> examine how power laws are best detected in practice: regression analysis of linear relationships in log-log scale (the standard method) results in many false positives (e.g. networks that might be better approximated by exponential or log-normal distributions). Sampling might also introduce false negatives <cite>Stumpf et al. 2005</cite>.
</text> 

<text>
EXAMPLES
distribution of number of papers published by scientists, distribution of cities by population, distribution of wealth, and
distribution of species among genera all obey a power law.
[Mitzenmacher, M., A brief history of generative models for power law and lognormal distributions, Internet Math. 1(2):226-251 (2004).] 

1999:
+ M. Faloutsos, P. Faloutsos, and C. Faloutsos observed a power law in their graph models of the Internet
+ Albert, Jeong, and Barabasi obtained similar results for the WWW

Scale-free networks appear to model economic constructs such as the Internet and
monopolies within industrial segments, because preferential attachment is essentially
the law of increasing returns of economics.
</text>

</document>



<document>
<tag>scale-free-models</tag>
<title>Models of scale-free network formation</title>


<document>
<tag>formation-barabasi-albert</tag>
<title>Barabasi-Albert model (scale-free networks)</title>

<text>
++
L: "a microrule called preferential attachment - that the probability a site will obtain a new link is directly proportional to the number of links it already has" (the <q>rich get richer</q> phenomenon).

<cite>Barabasi and Albert 1999</cite> demonstrated that power-law degree distributions can be generated by a <q>preferential attachment</q> growth process. This process is a well-known example of how local processes can determine the global properties of complex networks. 

L: Yule first observed preferential attachment in evolution (Yule, 1925): Darwinian algorithm = Connect the new node to an existing node with probability proportional to the number of links already connected to the existing node, i.e. its degree
[Yule, G. U., A Mathematical theory of evolution based on the conclusions of Dr. J. C. Willis, Phil. Trans. Roy. Soc. Lond. B 213:21-87 (1925).]
++ Yule-Simon distribution

L: the idea of nonrandomness as a factor in behavior and the connection between preferential attachment and nonrandom distributions occurred to Simon in 1955 [Simon, H. A., On a class of skew distribution functions, Biometrika 42(3/4):425-440 (1955).]

L: Preferential attachment describes an emergent process—that is, a process that results in a network topology that is not apparent by examination of the local algorithm, or microrule. It is not at all obvious that the result of repeated application of preferential attachment will result in a network with a degree sequence distribution that follows a power law. This realization would come 70 years later, when A.-L. Barabasi and R. Albert showed how to create a scale-free network by repeated application of preferential attachment.
</text>

<comment>
<title>Random resampling</title>

<text>
Alternatives for roulette wheel selection 

A) Weight normalization + cumulative weights + single random U[0,1] for each new sample
O(n) for a single sample, O(n^2) for n samples, O(nlog n) for n samples if binary search is employed

B) Wheel + multiple calls to an uniform random number generator for each new sample
O(n) for a single sample in the worst case, O(n^2) for n samples in the worst case, i.e. a extremely skewed distribution
O(k) for a single sample in the average case, O(kn) for n samples in the average case
Faster than the standard roulette wheel selection, despite higher number of calls to RNG ???
++ "B is faster when the weights are uniformly distributed, and slower when they are exponentially distributed"

++ "the resampling wheel aims to take advantage of the fact that we are going to select a large number of particles at once as opposed to "a particle at a time"."
++ "tradeoff seems to be that you want as small an interval as possible to minimize the number of particles you visit on each step but still is sufficiently random to approximate the desired distribution. If the interval was very small then all of your samples would reside on a tiny slice of the wheel. If the interval is too large then you waste time "visiting." 2 * max(w) assures that you get at least one "new" particle per iteration of the algorithm. Why not use max(w) instead? That would bias the probability of choosing the larger elements because elements close to max(w) in size are essentially guaranteed to be selected"
i.e.  2*wmax is a somewhat arbitrary value that balances keeping the tries to keep the algorithm efficient without overly biasing the results.
i.e. if the increment was less than wmax, you would be guaranteed to select the highest probability particle so the results would definitely be biased. If the increment was 10*wmax, you would be looping through alot more particles and you algorithm would be less efficient.


C) Walker's alias method, slightly faster, especially if there are many samples. 
O(n) setup time using Vose's algorithm (makes sense if you do lots of sampling) + samples in O(1).
An implementation in python can be found @ <url>http://code.activestate.com/recipes/576564/</url>, 

Walker's algorithm essentially arranges a given lot of sticks into equal-length rows: pick a row shorter than average and a row longer than average, split the longer to fill the shorter, iterate until they're all the same length.


Walker's method involves setting up \magic" tables of length nn, where nn is the smallest power of 2 that is \geq n.


ref. On the Alias Method for Generating Random Variables from a Discrete Distribution
     Richard A. Kronmal and Arthur V. Peterson, Jr.
     The American Statistician
     Vol. 33, No. 4 (Nov., 1979), pp. 214-218
     <url>http://www.jstor.org/discover/10.2307/2683739</url>

    "A Linear Algorithm For Generating Random Numbers With a Given Distribution" by Michael Vose
    IEEE  TRANSACTIONS ON SOFTWARE  ENGINEERING,  VOL.  17, NO.  9, 972-975  SEPTEMBER  1991
    <url>http://web.eecs.utk.edu/~vose/Publications/random.pdf</url>


ref. "Darts, Dice, and Coins: Sampling from a Discrete Distribution"
     Tutorial by Keith Schwarz, lecturer in Stanford's CS department: http://www.keithschwarz.com/darts-dice-coins/

++ http://www.google.com/patents/US5247677
   "Stochastic priority-based task scheduler
   Robert V. Welland, Walter R. Smith
   US Patent (Apple Computer, Inc.)
   Patent number: 5247677
   Filing date: May 22, 1992
   Issue date: Sep 21, 1993

++  L. Devroye, Non-Uniform Random Variate Generation, 1986, p. 107 ff., http://cg.scs.carleton.ca/~luc/rnbookindex.html
    Knuth, Stanford GraphBase, 1993, p. 392, http://tex.loria.fr/sgb.html
    Seminumerical Algorithms, second edition, exercise 3.4.1-7. 
    C++ hat random container by AngleWyrm, http://home.comcast.net/~anglewyrm/hat.html

++ non-random resampling ;-) "sorting the weights largest to smallest and then calculating exactly how many particles correspond to each of those weights. Because it isn't homework, I assume it is okay to post this non-random resampling algorithm."
</text>

<text>
Evaluation (Matlab):
</text>

<code>
for i=1:N
  distribution(i) = sum(new==i)/N; % frequency of index i
endfor

error = sqrt(sum((distribution - weight).^2))/N;
</code>

<text>
Applications: Preferential attachment, selection method in genetic algorithms (a.k.a. fitness proportionate selection or roulette-wheel selection), resampling in particle filters (e.g. robot localization).
</text>

<text>
ref. ON RESAMPLING ALGORITHMS FOR PARTICLE FILTERS
<url>http://www.control.isy.liu.se/~schon/Publications/HolSG2006.pdf</url>
</text>

</comment>

<algorithm>
<title>Choosing items in proportion to their importance weights</title>
<code>
# 1) Roulette wheel: inefficient <eqn>O(n^2)</eqn> implementation

# Weight normalization

W = sum(weight)

for i in range(N): 
    weight[i] = weight[i]/W

# Resampling

for i in range(N):
    r = random.random()
    index = 0
    s = weight[0]
    while (index&lt;N) and (s&lt;r):
        index = index + 1
        s = s + weight[index]
    if (index==N):
        index = N-1
    new[i] = element[index]


# 2) Resampling wheel: starting from a (uniformly) random index

# Initial selection

index     = int(random.random() * N)
beta      = 0.0
maxWeight = max(weight)

# Resampling: U[0,2*maxWeight]

for i in range(N):
    beta += 2.0 * maxWeight * random.random()
    while (beta &gt; weight[index]):
        beta -= weight[index]
        index = (index+1) % N
    new[i] = element[index]

</code>
</algorithm>


<text>
++ Linear preferential attachment yields scale-free networks with an exponent of 3. Refined attachment rules that vary node attractiveness yield scale-free networks with exponents between 2 and 3.
</text>

<text>
++ When new links involve a cost, i.e. they cost energy or occupy space, the degree distribution becomes truncated for high degrees <cite>Amaral et al. 2000</cite>. Networks that exhibit a scale-free behavior only through a range of node degrees are called broad-scale networks.
</text>

</document>


<text>
Alternative formation model: <cite>Alava and Dogorotsev 2005</cite>
</text>

</document>


<document>
<tag>scale-free-dynamics</tag>
<title>The dynamics of scale-free networks</title>

<text>
L: Albert, Jeong, and Barabasi observed that scale-free networks were extremely resilient
against random attacks, but extremely vulnerable to systematic attacks on hubs
(Albert, 2000). This makes sense—a random attack will most likely strike and destroy
a node with only a few links, because a scale-free network has many such nodes. On
the contrary, since hubs are rare, it is unlikely that a hub is attacked. But a hub has
many links, and so its demise damages a large percentage of the network. Let pc
be the fraction of damaged nodes that dismantles the network. When pc is high,
the network is resilient, because many nodes must be knocked out to dismantle the
network. When it is low, the network is vulnerable. In simulations, Albert et al.
found threshold values of pc = 28% for random networks versus nearly 99% for
scale-free networks under random attacks; that is, a random network dismantles
when an average of 28% of its nodes are damaged. But the tables are turned when
hubs are systematically attacked—only 18% of the nodes need to be attacked to dismantle
a scale-free network. Thus, a scale-freenetwork is more vulnerable than a
random network when its hubs are targeted.

2000 Albert, Jeong, Barabasi: Scale-free networks are resilient if hubs are protected (Internet's "Achilles heel")
  [Albert, R., H. Jeong, and A. L. Barabasi, The Internet's Achilles' heel: Error and attack tolerance of complex networks, Nature 406:378-382 (2000).]
</text>

<text>
L: In related work, Pastor-Satorras and Vespignani observed that populations forming
a scale-free network have no minimum epidemic threshold that prevents an infectious
disease from recurring (Pastor-Satorras, 2001). Once an infection enters a network, it
rises and falls repeatedly. Persistent epidemics are real—they occur in human networks
as well as on the Internet.


2001 Pastor-Satorras, Vespignani: Claim no epidemic threshold in scale-free networks; Internet susceptible to SIS viruses
  [Pastor-Satorras, R. and A. Vespignani, Epidemic spreading in scale-free networks, Phys. Rev. Lett. 86(14):3200-3203 (2001).]
</text>

<text>
L: Wang and coworkers showed the initial claim of Pastor-Satorrus to be generally
false (Wang, 2003a). Instead, persistence of an infection is determined not by the network's
degree sequence but by its spectral radius, which is defined as the largest nontrivial
eigenvalue of a network's connection matrix. Therefore, network topology
determines its susceptibility to epidemics, but not because it is scale-free. This profound
result has significant implications for fighting both kinds of viruses—Internet
and human. It also has implications for the product marketer.
</text>


<text>
MORE...
</text>

<text>
1999 Dorogovtsev, Mendes, Samukhim, Krapivsky, Redner: Exact solution to scale-free network degree sequence
[Dorogovtsev, S. N., J. F. F. Mendes, and A. N. Samukhin, Structure of growing networks with
preferential linking, Phys. Rev. Lett. 85(21):4633-4636 (2000).]
[Krapivsky, P. L., S. Redner, and F. A. Leyvraz, Connectivity of growing random networks,
Phys. Rev. Lett. 85(21):4629-4632 (2000).]
</text>


<text>
<cite>Caldarelli 2007</cite>
<cite>Cohen and Havlin 2003</cite>
<cite>Barabasi and Bonabeau 2003</cite>
</text>


</document>

</document>



<document>
<tag>strategic-network-formation</tag>
<title>Strategic network formation</title>

<text>
cf. Jackson 6
</text>

</document>




<document>
<tag>formation-notes</tag>
<title>Bibliographic notes</title>

<text>
<cite>Sole and Valverde 2004</cite> arrange network classes in a qualitative space by considering three dimensions: randomness, heterogeneity, and modularity. The first introduces the amount of randomness involved in the process of network's building. The second measures how diverse is the link distribution and the third would measure how modular is the architecture. The position of different examples are only a visual guide. The domain
of highly heterogeneous, random hierarchical networks appears much more occupied than others. Scale-free like networks belong to this domain.

Each class results from a different formation process and exhibits different patterns of behavior. 

Not all niches in this space are occupied by real-world networks (empty regions might correspond to unrealistic growth strategies or unstable network configurations).
</text>

<text>
++
<cite>Jackson 2009</cite>
<cite>Lewis 2009</cite>
</text>

<text>
Hierarchical models can combine scale-free degree distributions and high clustering coefficients <cite>Ravasz and Barabasi 2003</cite>
</text>


</document>



</document>

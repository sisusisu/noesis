<?xml version="1.0"  encoding="ISO-8859-1" ?> 
<!DOCTYPE sys-ents [ <!ENTITY bibliography SYSTEM "bibliography.xml"> ]> 
<?xml-stylesheet type="text/xsl" href="../book.xsl"?>


<document>
&bibliography;
<tag>dynamics</tag>
<title>Network Dynamics</title>

<text>
A network is dynamic if its topology or other properties change as a function of time
</text>

<text>
++ <cite>Barrat et al. 2008</cite> <cite>Bar-Yam 2003</cite>  <cite>Ganguly et al. 2009</cite>
</text>

<text>
++ Classics <cite>Newman et al. 2006</cite>
</text>

<text>
++ Evolution <cite>Leskovek et al. 2005</cite> <cite>Dorogovtsev and Mendes 2002</cite> <cite>Dorogovtsev and Mendes 2003</cite> <cite>Pastor-Satorras and Vespignani 2007</cite>
</text>

<text>
Chapter 7 @ <cite>Lewis 2009</cite>: <q>Emergence,</q> introduces new self-organizing principles
for networks and shows how to custom-design networks of arbitrary degree sequence
distribution; 
</text>

<text>
Chapter 12 @ <cite>Lewis 2009</cite>, <q>Netgain,</q> is an exploration of business
models - relating the famous Schumpeter creative destruction process to an emergent
process, and mapping the Bass and Fisher-Pry equations onto networks. It is comforting
to verify the Bass-Fisher-Pry equations for networks, but furthermore, I
show how these classical models may be extended to multi-product markets and oligopolies.
</text>


<!-- Game theory -->

<document>
<tag>game-theory</tag>
<title>Game theory</title>

<text>
K: a theory of behavior .... provides models of individual behavior in settings where outcomes depend on the behavior of others.

K: settings in which a group of people must simultaneously choose how to act, knowing that the outcome will depend on the decisions made by all of them.

K: we abstract such situations with interdependent behavior into a common framework, wherein a collection of individuals must each commit to a strategy, thereby receiving a payoff that depends on the strategies chosen by everyone... This general framework allows us to make predictions about how people will behave in a range of situations. A fundamental part of this framework is the notion of equilibrium – a state that is “self-reinforcing” in that it provides no individual with an incentive to unilaterally change his or her strategy, even if that individual knows how others will behave.

K: e.g. One natural example is the problem of choosing a driving route through a network of highways at a time when traffic is heavy. For a driver in such a situation, the delays experienced depend on the pattern of traffic congestion arising not just from the driver’s choice of route, but also from the choices made by all other drivers. In this example, the network plays the role of a shared resource, and the combined actions of its users can either congest this resource or use it more efficiently. In fact, the interactions among people’s behavior can lead to counterintuitive effects; for example, adding resources to a transportation network can in fact create incentives that seriously undermine its efficiency, in a phenomenon known as Braess’s Paradox [76].

K: e.g. bidding in an auction. If a seller is trying to sell a single item using an auction, then the success of any one bidder in the auction (whether she gets the item, and how much she pays) depends not just on how she bids but also on how everyone else bids; an optimal bidding strategy should take this into account. Here too, counterintuitive effects are at work: for example, if the seller introduces more aggressive pricing rules into the auction, he can make the strategic behavior of the bidders much more complex, and in particular induce optimal bidding that offsets whatever gains he might have expected to make from the new rules. Auctions represent a basic kind of economic interaction that we will generalize to more complex patterns of interactions in networks...

APPLICATIONS

K: One natural setting for this exploration is in models of trade and other forms of economic activity. The interactions among buyers and sellers, or pairs of counterparties to a trade or loan, naturally forms a network...
</text>

</document>

<!-- Spectral analysis -->

<document>
<tag>graph-theory-spectral</tag>
<title>Spectral analysis</title>

<text>
L: Spectral decomposition of the adjacency and Laplacian matrices provides valuable
insight into the nature of a graph. Spectral
properties of graphs are used to model behaviors such as the spread of contagions,
rumors, ideas, and group consensus, as well as the spread of chaos
throughout a graph. 

The technique is similar to methods used to understand the behavior of linear systems such
as a vibrating string in a musical instrument, states of a particle in quantum mechanics,
or various other electromechanical systems. (
</text>

<text>
L: We can think of a matrix as a transformation of linear system as it moves in
time and space according to its dynamical equation D[A] = AX, where D is a linear
operator, A is some kind of linear transformation, and X is the state of the system. For
example, D might be the time derivative operator, and A might be the damping forces
acting on a mechanical system, such as a robotic arm or automobile suspension system.
</text>

<text>
L: A well-behaved linear system will cycle through some kind of pattern.
We can determine the nature of this pattern by decomposing the system's response
to a stimulus into a set of fundamental modes or basis vectors in a mathematical
process called spectral decomposition. These basis vectors are called orthonormal
vectors or eigenvectors.
</text>

<text>
Specifically, if \lambda is a diagonal matrix containing eigenvalues,
det [A - \lambda I] = 0, where det[] is the determinant of the matrix [ ].
</text>

<text>
At the risk of oversimplification, spectral analysis is the process of finding the basic
vibrational modes (harmonics) of a linear system and expressing them in terms of
constants called eigenvalues. The largest such eigenvalue, typically denoted l1, is
of particular interest because it represents the dominant mode of the dynamic
system. Furthermore, if l1 &lt; 0, the vibration eventually dies out; otherwise, it
increases and leads to an unstable system.
</text>

<text>
... we use spectral radius to explain how epidemics travel through a network,
and spectral gap to explain stability—or the lack of it—in a network.

... spectral radius/gap are determined completely by the degree sequence of a graph, and therefore, is a measure of a graph's topology

</text>

<text>
- The spectral radius \rho(G) is computed from the adjacency matrix: it is the largest non-trivial (i.e. non-zero) eigenvalue of a graph's adjacency matrix. Spectral radius eigenvalues are also called the characteristic eigenvalues because they characterize the topology of a graph in succinct terms.

- The spectral gap \sigma(G) is computed from the Laplacian matrix: it is the largest non-trivial (i.e. non-zero) eigenvalue of a graph's Laplacian matrix. 
</text>

</document>


<!-- Diffusion -->

<document>
<tag>diffusion</tag>
<title>Diffusion through networks (i.e. signal propagation)</title>


<text>
K: Population Effects. If we observe a large population over time,
we see a recurring pattern by which new ideas, beliefs, opinions, innovations, technologies,
products, and social conventions are constantly emerging and evolving. Collectively,
we can refer to these as social practices [382] (e.g., holding opinions, purchasing
products, or behaving according to certain principles) that people can choose to adopt
or not. As we watch a group or society over time, we see that new practices can be
introduced that either become popular or remain obscure; meanwhile, established practices
can persist or potentially fade over time...

PEER EFFECTS
The way in which new practices spread through a population depends in large part on
the fact that people influence each other’s behavior. In short, as you see more and more
people doing something, you generally become more likely to do it, too. Understanding
this process, and what its consequences are, is a central issue for our understanding of
networks and aggregate behavior.

At a surface level, one could hypothesize that people imitate the decisions of others
simply because of an underlying human tendency to conform: we have a fundamental
inclination to behave as we see others behaving. This observation is clearly important,
but as an explanation it leaves some crucial questions unresolved. In particular, by
taking imitation as a given, we miss the opportunity to ask why people are influenced
by the behavior of others. This is a broad and difficult question, but in fact it is possible
to identify multiple reasons why even purely rational agents – individuals with no a
priori desire to conform to what others are doing – nonetheless copy the behavior of
others.

+ 1) INFORMATION
One class of reasons is based on the fact that the behavior of others conveys information.
You may have some private information on which to base a decision between
alternatives, but if you see many people making a particular choice, it is natural to
assume that they too have their own information, and to try to infer how other people
are evaluating different choices from how they are behaving. In the case of a Web site
like YouTube or Flickr, the observation that a lot of people use it can suggest that these
people know something about its quality. Similarly, seeing that a certain restaurant
is extremely crowded every weekend can suggest that many people think highly of
it. But this sort of reasoning raises surprisingly subtle issues: as many people make
decisions sequentially over time, the later decisions can be based in complex ways on a
mixture of private information and inferences from what has already happened, so that
the actions of a large set of people can in fact be based on surprisingly little genuine
information. In an extreme form of this phenomenon we may get information cascades,
where even rational individuals can choose to abandon their private information and
follow a crowd.

+ 2) BENEFITS
There is a completely different but equally important class of reasons why people
may imitate the behavior of others – when a direct benefit can be gained from aligning
one’s behavior with that of others, regardless of whether they are making the best
decision. ... Such network effects amplify the success of products and technologies that are already
doing well; in a market where network effects are at work, the leader can be difficult
to displace. Still, this type of dominance is not necessarily permanent; as we will see
later, it is possible for a new technology to displace an old one if it offers something
markedly different or when it starts in a part of the network where there is room for the
new technology to take hold.

These considerations show how popularity as a general phenomenon is governed
by a “rich get richer” feedback process in which popularity tends to build on itself. It
is possible to build mathematical models for this process that include predictions for
the distribution of popularity that are borne out by empirical data – a picture in which
society’s attention is divided between a small number of prominent items and a “long
tail” of more obscure ones.


STRUCTURE
The underlying mechanisms, based on information and direct benefits, are present both
at the level of whole populations and at a local level in the network, between an
individual and his or her set of friends or colleagues. In many cases you may care more
about aligning your own behavior with the behavior of your immediate neighbors in
the social network, rather than with the population as a whole.

When individuals have incentives to adopt the behavior of their neighbors in the
network, there can be cascading effects, in which a new behavior starts with a small set
of initial adopters and then spreads radially outward through the network.

e.g. the diffusion of technologies can be blocked by
the boundary of a densely connected cluster in the network – a “closed community”
of individuals who have a high amount of linkage among themselves, and hence are
resistant to outside influences.

Cascading behavior in a network is sometimes referred to as “social contagion”
because it spreads from one person to another in the style of a biological epidemic

fundamental differences in the underlying mechanisms between social and biological
contagion; social contagion tends to involve decision making on the part
of the affected individuals, whereas biological contagion is based on the chance of
catching a disease-causing pathogen through contact with another individual. But the
network-level dynamics are similar, and insights from the study of biological epidemics
are also useful in thinking about the processes by which things spread in
networks.
</text>


<text>
L: Chapter 8 @ <cite>Lewis 2009</cite>, <q>Epidemics,</q> extends the elegant work of Z. Wang,
Chakrabarti, C. Wang, and Faloutsos, to the exciting new endeavor of designing
antigen countermeasures for the Internet. This work can be used to explain human
epidemics as well as epidemics that sweep across the Internet. 
</text>


<text>
L: In 1927, Kermack and McKendrick published the first mathematical model of the spread of an infection in a biological population (Kermack, 1927). The Kermack-McKendrick epidemic model is a nonnetwork model, but it set the stage for two important innovations to come: 

(1) it explained the spread of a contagion along (social) links connecting (individual) nodes, and 

(2) it coincidentally described new-product adoption—diffusion of technology—and how product information spreads like an infectious disease
throughout a social network.
[Kermack, W. O. and A. G. McKendrick, A contribution to the mathematical theory of epidemics. Proc. Roy. Soc. Lond. A 115:700-721 (1927).]
</text>

<text>
L: Solomonoff and Rappaport were the first to apply the ideas of epidemics to RANDOM networks (Solomonoff, 1951)
[Solomonoff, R. and A. Rapoport, Connectivity of random nets, Bull. Math. Biophys. 13:107-117 (1951).]
</text>

<text>
L: the idea of nonrandomness as a factor in behavior and the connection between preferential attachment and nonrandom distributions occurred to Simon in 1955 (Simon, 1955)
[Simon, H. A., On a class of skew distribution functions, Biometrika 42(3/4):425-440 (1955).]
</text>

<text>
L: NON-NETWORK MODELS

Bass, Fisher, and Pry model new-product adoptions as the propagation of an infectious disease (Bass, 1969, 2001; Norton, 1987). This work extended the Kermack-McKendrick epidemic model to the new field of marketing and prepared the way for network-based product diffusion models
[Bass, F. M., A new product growth for model consumer durables, Manage. Sci. 15:215-227 (1969).]
[Bass, P. I. and F. M. Bass, Diffusion of Technology Generations: A Model of Adoption and Repeat Sales, Working Paper, Bass Economics Inc. (www.basseconomics.com), Frisco, TX, 2001.]
[Norton, J. H. and F. M. Bass, A diffusion theory model of adoption and substitution for successive generations of high-technology products, Manage. Sci. 33(9):1069-1086 (Sept. 1987).]


1969 Bass: Diffusion of innovation in populations (non-network model)
  [Bass, F. M., A new product growth for model consumer durables, Manage. Sci. 15:215-227 (1969).]

1971 Fisher, Pry: Diffusion by product substitution (non-network model)
  [J. C. Fisher and R. H. Pry (1971) "A Simple Substitution Model of Technological Change", Technological Forecasting &amp; Social Change, vol. 3, no. 1]

</text>


<text>
L: the rate of spreading and persistence of an infection is determined completely by a network's topological structure as well as the infectiousness of the contagion. Thus some networks are more prone to epidemics than are others. Furthermore, understanding the relationship between network topology and the spread of an infection tells us how best to stop the spread.

1996 Kretschmar, Morris: spread of infectious disease - contagion driven by largest connected component
  [Kretzschmar, M. and M. Morris, Measures of concurrency in networks and the spread of infectious disease, Math. Biosci. 133:165-96 (1996).]

2003 Wang, Chakrabarti, Wang, Faloutsos: Spread of epidemics determined by network's spectral radius, largest eigenvalue of connection matrix
  [Wang, Z., D. Chakrabarti, C.Wang, and C. Faloutsos, Epidemic spreading in real networks: an eigenvalue viewpoint, Proc. 22nd Intnatl. Symp. Reliable Distributed Systems, Oct. 6-18, 2003.]
</text>

<text>
EXAMPLES
- computer viruses spreading in networks such as the Internet.
- The spread of information (advertising or "buzz") in a social network is much like the spread of an epidemic.
</text>
</document>



<document>
<tag>search</tag>
<title>Search on networks</title>

<text>
K: ... the way people can explore chains of social contacts for information or
referrals to others. The surprising effectiveness with which people are able to accomplish
such tasks, confirmed by both experiments and everyday experience, suggests
characteristic patterns of structure at the network level that help facilitate these types
of activities.
</text>


<text>
++ 1999 Walsh: Difficulty of search in small worlds using local properties
[Walsh, T., Search in a small world, IJCAI'99, Proc. 16th Intnatl. Joint Conf. Artificial
Intelligence, Stockholm, Sweden, Morgan Kaufmann Publishers, San Francisco, 1999,
Vol. 2, pp. 1172-1177.]

++ 2000 Kleinberg: Shows O(n) search in small world using "Manhattan distance"
[Kleinberg, J. M., Navigation in a small world, Nature 406:845 (2000).]

++ 2001 Tadic, Adamic: Use of local information can speed search on scale-free networks
[Tadic, B., Adaptive random walks on the class of web graphs, Eur. Phys. J. B 23(2):221-228 (2001).]
[Tadic, B., Dynamics of directed graphs: The world-wide web, Physica A 293(1-2):273-284 (2001).

++ 
[Walsh, T., Search on high degree graphs, IJCAI'01, Proc. 17th Intnatl. Joint Conf. Artificial
Intelligence, Seattle, Morgan Kaufmann Publishers, San Francisco, 2001, pp. 266-274.]
</text>


</document>


<document>
<tag>synchronization</tag>
<title>Synchronization and stabilization (i.e. conflicts and consensus)</title>

<text>
++ <cite>Arenas et al. 2008</cite>
</text>

<text>
L: "Strogatz studied the impact of network structure on complex adaptive systems in
physics as well as explaining why hearts beat in a regular synchronized pattern in
mammals, and why a certain species of firefly rhythmically chirps in unison without centralized
control. It appeared that living organisms tend to synchronize their behavior
without global knowledge." 

L: understanding of how and why network synchronization occurs in physical and biological systems also explains
the conditions for arriving at a consensus by a group of people, how best to conduct product marketing campaigns, and how corporations rise to become a monopoly. Synchronization is a byproduct of the structure of 'living networks.'

L: Networks tend to be structured in such a way that synchronization is more likely than chaos, simply because unstable systems cannot survive in natur
</text>

<text>
L: Bonacich was perhaps the first social scientist to realize
that influence in a social network could be mathematically represented using the connection
matrix of the network (Bonacich, 1972). The nodes represent individuals, and
weights on directed links represent the degree of influence one individual has on
another.3 If person A influences the decision of person B, and person B influences
the decision of person C, and so on, what is the overall effect on group consensus?
Will a chain of influences propagate through a network and eventually settle down
to a common value? Bonacich naively claimed that consensus would eventually be
reached, and proposed that the consensus be computed by raising the weighted connection
matrix to the nth power, where n is the number of nodes in the network.
[Bonacich, P., Factoring and weighing approaches to clique identification, J. Math. Sociol.
2:113-120 (1972).]
</text>

<text>
L: Marketing gurus note that highly connected people are superspreaders—people
who accelerate the spread of buzz—new-product information, simply because they
are highly connected (Rosen, 2000). But social scientists have long known of the
power of the middleperson or intermediary—actors who connect other actors. If
the only way actor A can communicate with actor C is by going through actor B,
then B has power over A and C. Thus, social scientists define betweenness as the
number of paths that must run through an actor to connect with other actors. So, in
addition to connectedness, an actor derives influence by serving as an intermediary.
Does betweenness give an actor more influence than connectedness?
[Rosen, E., The Anatomy of Buzz, Doubleday-Random House, 2000.]
</text>

<text>
L: More rigorously, a network can be regarded as a coupled system. The system is
composed of nodes that take on values called states, and links that establish the
inputs and outputs to nodes. The state of the network is the union of the states of
all of its nodes. Signals (values) propagate along links, from node to node, and
alter the node's states. If we plot the change in state versus time, we might observe
oscillations, dampening, or convergence to a certain state—the so-called fixed
point—and remain there, forever. Under what conditions does a network oscillate
or converge? ... A network is said to sync when the value of its nodes reach
a fixed point—a value that ceases to change once reached. We answer the question
"What properties or conditions are necessary and sufficient for a network to sync?"
The answer leads to a general theory of stability in networks.

L: Stability. A dynamic network is stable if the rate of change in the state of its
nodes/links or its topology either diminishes as time passes or is bounded
by dampened oscillations within finite limits. For example, the regular and
rhythmic beating of an animal’s heart is controlled by a stable network of
nerves that regulate the pacemaker, the loss of a power plant in the electrical
power grid stabilizes quickly by switching from one source to another
without disruption in supply, or the loss of a coworker causes short-term reallocation
of responsibility without organizational failure.
</text>

<text>
++ Structural balance <cite>Easley and Kleinberg 2010</cite>
</text>

<text>
Kuramoto provided a mathematical basis for studying synchronization in coupled
linear systems (Kuramoto, 1984). 
[Kuramoto, Y., Chemical Oscillations, Waves, Turbulence, Springer-Verlag, 1984; republished
by Dover Publications, 2003 (www.doverpublications.com).]

His work would influence Strogatz a decade later,
and have a major impact on the convergence between network science and control
theory. For example, Kuramoto's work led Strogatz to observe automatic synchronization
in small-world networks. Strogatz claimed that synchronization is simply a
property of all small worlds (Strogatz, 2003). This turns out to be false...
[Strogatz, S., SYNC: The Emerging Science of Spontaneous Order, Hyperion, 2003.]
</text>

<text> 
L: Chapter 9 @ <cite>Lewis 2009</cite>, <q>Synchrony,</q> pushes the early work of Watts to new levels—claiming that
network synchronization is merely a special case of linear system stability. Simple
eigenvalue tools can be used to determine the stability and synchrony of almost
any linear network. 


2002 Wang, Chen, Barahona, Pecora, Liu, Hong, Choi, Kim, Jost, Jo: Sync in small worlds equivalent to stability in coupled system
  [Wang, X. and G. Chen, Synchronization in small-world dynamical networks, J. Bifurcation Chaos 12(1):187-192 (2002).]
  [Wang, X. and G. Chen, Synchronization in scale-free dynamical networks: Robustness and fragility, IEEE Trans. Circuits Syst. I 49:54-62 (2002)]
  [Barahona, M. and L. M. Pecora, Synchronization in small-world systems, Phys. Rev. Lett. 89:054101 (2002).]
  [Hong, H., M. Y. Choi, and B. J. Kim, Synchronization on small-world networks, Phys. Rev. E 65:026139 (2002),]
  [Jost, J. and M. P. Joy, Spectral properties and synchronization in coupled map lattices, Phys. Rev. E 65(1):016201 (2002).]

2003 Strogatz: Synchronization of crickets, heartbeats
  [Strogatz, S., SYNC: The Emerging Science of Spontaneous Order, Hyperion, 2003.]

2006 Atay Synchronization in networks with degree sequence distribution—application to networks
  [Atay, F. M., T. Biyikoglu, and J. Jost, Synchronization of networks with prescribed degree distributions, IEEE Trans. Circuits Syst. I 53(1):92-98 (2006).]
</text>

<text>
L: Chapter 10 @ <cite>Lewis 2009</cite>, <q>Influence Networks,</q> is mostly new material and
suggests what conditions must be met in order for a social network to come to consensus.
As it turns out, it is not easy for groups to agree! 

...

2007 Gabbay: Consensus in influence networks—linear and nonlinear models
  [Gabbay, M., The effects of nonlinear interactions and network structure in small group opinion dynamics, Physica A 378:118-126 (www.elsevier.com/locate/physa) (2007).]

Consider a group of people attempting to arrive at a consensus
(Gabbay, 2007). Each member of the group starts with an initial position, and
attempts to influence his or her neighbor's position by exerting a positive or negative
influence on nearest neighbors. Influence spreads like an epidemic, but rather than
infecting or not, the influence sways the position of adjacent nodes

e.g. Atay network, nodes take on a
value in the interval [-1, +1], representing disagreement or agreement, or some fraction
in between. As influence spreads, each node value changes. If all nodes reach the
same value, after some period of time, we say that the network has reached a consensus.
If nodes never reach a consensus, we say that the network diverges.
...
consensus is reached when the influence network's largest nontrivial state matrix eigenvalue
is bounded by one, and there are no conflicts in the network. Curiously, the most
influential node in the network is the one less influenced by other nodes.
</text>

</document>


<document>
<tag>robustness</tag>
<title>Robustness / Vulnerability (i.e. percolation &amp; network resilience)</title>


<text>
++ <cite>Motter 2004</cite> <cite>Huang et al. 2011</cite>
</text>

<text>
++ Internet <cite>Cohen et al. 2000</cite> <cite>Cohen et al. 2001a</cite> <cite>Cohen et al. 2001b</cite>
</text>


<text>
L: Chapter 11 @ <cite>Lewis 2009</cite>, <q>Vulnerability,</q>
builds on the PhD dissertation of Waleed Al-Mannai, who formalized and extended
my own work on network risk. Al Mannai's theory is being used on a daily basis to
evaluate critical infrastructure systems and protect them against natural and synthetic
(anthropogenic, humanmade) attacks. This has made a profound impression on the
practice of homeland security. 
</text>

</document>


</document>
